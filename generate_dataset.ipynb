{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_464704/441343652.py:9: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "        columns_list = df.columns.values.tolist()\n",
    "        isnull_list = df.isnull().sum().values.tolist()\n",
    "        isunique_list = df.nunique().values.tolist()\n",
    "        dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "        list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "        df_stat_val = pd.DataFrame(list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"])\n",
    "        print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:generate_dataset:Loading data from /media/data1/datasets/DeepCoro/2b_CathReport_HEMO_MHI_MERGED_2017-2024_VIDEO_LEVEL.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration:\n",
      "apply_mappings: true\n",
      "assign_status: true\n",
      "filters:\n",
      "  contrast_agent_class: 1\n",
      "  main_structures:\n",
      "  - Left Coronary\n",
      "  - Right Coronary\n",
      "  status:\n",
      "  - diagnostic\n",
      "output_settings:\n",
      "  include_index: false\n",
      "  separator: \"\\u03B1\"\n",
      "report_settings:\n",
      "  coronary_specific: true\n",
      "sampling:\n",
      "  enabled: true\n",
      "  label_column: status\n",
      "  n_per_group: 9\n",
      "train_test_split:\n",
      "  enabled: true\n",
      "  patient_column: CathReport_MRN\n",
      "  random_state: 42\n",
      "  save_separate_files: false\n",
      "  test_ratio: 0.2\n",
      "  train_ratio: 0.7\n",
      "  val_ratio: 0.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:generate_dataset:Loaded 843499 records with 788 columns\n",
      "INFO:generate_dataset:Created bypass_graft column from Conclusion\n",
      "INFO:generate_dataset:Sorted data by StudyInstanceUID and SeriesTime for temporal ordering\n",
      "INFO:generate_dataset:Assigning procedure status based on PCI timing...\n",
      "INFO:generate_dataset:Status distribution: {'PCI': 360840, 'diagnostic': 334320, 'POST_PCI': 112612, 'unknown': 35727}\n",
      "INFO:generate_dataset:Applying hard filters...\n",
      "INFO:generate_dataset:Dropped External_Exam: 843499 -> 843499 rows\n",
      "INFO:generate_dataset:Dropped bypass_graft: 738052 rows remaining\n",
      "INFO:generate_dataset:Filtered stenosis columns: 738052 rows remaining\n",
      "INFO:generate_dataset:Status filter applied: ['diagnostic']\n",
      "INFO:generate_dataset:Main structure filter applied: ['Left Coronary', 'Right Coronary']\n",
      "INFO:generate_dataset:Contrast agent filter applied: 1\n",
      "INFO:generate_dataset:Dataset filtered from 843499 to 167134 rows\n",
      "INFO:generate_dataset:Generating medical reports...\n",
      "100%|██████████| 167134/167134 [02:09<00:00, 1286.47it/s]\n",
      "INFO:generate_dataset:Generated reports for 167134 records\n",
      "INFO:generate_dataset:Split distribution: {'train': 117120, 'test': 33157, 'val': 16857}\n",
      "INFO:generate_dataset:Unique patients per split: {'test': 5625, 'train': 19681, 'val': 2811}\n",
      "INFO:generate_dataset:Saved dataset with splits to reports/dataset_with_splits.csv\n",
      "INFO:generate_dataset:Sampling from train split only (117120 rows)\n",
      "INFO:generate_dataset:Sampling 9 records per status...\n",
      "INFO:generate_dataset:Saved 9 diagnostic samples to reports/samples/sample_diagnostic.csv\n",
      "INFO:generate_dataset:Dataset processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Add the dataset_creation directory to the path (if running from parent directory)\n",
    "if 'dataset_creation' not in sys.path:\n",
    "    sys.path.append('dataset_creation')\n",
    "\n",
    "# Import the dataset generation functions\n",
    "from generate_dataset import (\n",
    "    create_default_config,\n",
    "    load_data,\n",
    "    apply_hard_filters,\n",
    "    generate_reports,\n",
    "    sample_by_status,\n",
    "    process_dataset,\n",
    "    MAIN_STRUCTURE_MAP,\n",
    "    DOMINANCE_MAP\n",
    ")\n",
    "\n",
    "\n",
    "# Load config from yaml file\n",
    "config_path = \"dataset_creation/config_template.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))\n",
    "\n",
    "process_dataset('/media/data1/datasets/DeepCoro/2b_CathReport_HEMO_MHI_MERGED_2017-2024_VIDEO_LEVEL.parquet', 'reports/', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_464704/1580111087.py:4: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  df_merged = pd.read_csv('reports/dataset_with_splits_20250801.csv', sep='α')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_merged = pd.read_csv('reports/dataset_with_splits_20250801.csv', sep='α')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Split\n",
       "train    117120\n",
       "test      33157\n",
       "val       16857\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                                                                     \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has no significant stenosis.\\nthe distal LAD has no significant stenosis.\\nD1 branch has no significant stenosis.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has no significant stenosis.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nthe LEFT PDA has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is left dominant.\n",
       "1                                                                     \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has no significant stenosis.\\nthe distal LAD has no significant stenosis.\\nD1 branch has no significant stenosis.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has no significant stenosis.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nthe LEFT PDA has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is left dominant.\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                          \\nThis is a right coronary artery.\\nthe proximal RCA has no significant stenosis.\\nthe mid RCA has no significant stenosis.\\nthe distal RCA has no significant stenosis.\\nthe PDA has no significant stenosis.\\nthe posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                          \\nThis is a right coronary artery.\\nthe proximal RCA has no significant stenosis.\\nthe mid RCA has no significant stenosis.\\nthe distal RCA has no significant stenosis.\\nthe PDA has no significant stenosis.\\nthe posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "4                                                                                                                                                                         \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has mild stenosis (~20.0%).\\nthe distal LAD has no significant stenosis.\\nD1 branch has no significant stenosis.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has no significant stenosis.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "5                                                                                                                                                                         \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has mild stenosis (~20.0%).\\nthe distal LAD has no significant stenosis.\\nD1 branch has no significant stenosis.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has no significant stenosis.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "6                                                                                                                                                                         \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has mild stenosis (~20.0%).\\nthe distal LAD has no significant stenosis.\\nD1 branch has no significant stenosis.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has no significant stenosis.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "7    \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has severe stenosis (~70.0%), moderate calcifications, and bifurcation lesion (Medina Bifurcation 1.1.0).\\nthe distal LAD has severe stenosis (~80.0%), and minimal calcifications.\\nD1 branch has severe stenosis (~80.0%), and minimal calcifications.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has severe stenosis (~70.0%), and minimal calcifications.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "8                                                                                                                                                                                                                                                                                                                                                   \\nThis is a right coronary artery.\\nthe proximal RCA has severe stenosis (~70.0%), and minimal calcifications.\\nthe mid RCA has severe stenosis (~70.0%), and minimal calcifications.\\nthe distal RCA has severe stenosis (~70.0%), and minimal calcifications.\\nthe PDA has no significant stenosis.\\nthe posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "9                                                                                                                                                                        \\nThis is a left coronary artery.\\nthe Left Main Coronary Artery (LMCA) has no significant stenosis.\\nthe proximal LAD has no significant stenosis.\\nthe mid LAD has no significant stenosis.\\nthe distal LAD has no significant stenosis.\\nD1 branch has no significant stenosis.\\nD2 branch has no significant stenosis.\\nthe distal LCX has no significant stenosis.\\nOM1 has no significant stenosis.\\nOM2 has no significant stenosis.\\nRamus has no significant stenosis.\\nleft posterolateral branch has no significant stenosis.\\nThe coronary circulation is right dominant.\n",
       "Name: Report, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_merged.Split.value_counts())\n",
    "display(df_merged.Report.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coro = pd.read_parquet('/mnt/data1/datasets/DeepCoro/2b_CathReport_HEMO_MHI_MERGED_2017-2024_VIDEO_LEVEL.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_merged.FileName.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show report where mid_lad_cto == 1.0\n",
    "print(\"Report with mid_lad_cto == 1.0:\")\n",
    "display(df_merged[['Report','primary_angle','secondary_angle', 'main_structure_class']].head(n=1))\n",
    "\n",
    "# Show report where mid_lad_collateral == RCA\n",
    "print(\"\\nReport with mid_lad_collateral == RCA:\")\n",
    "display(df_merged[df_merged['mid_lad_collateral'] == 'RCA'][['CathReport_MRN','Report']].head(5))\n",
    "\n",
    "# Show report where leftmain_bifurcation is present\n",
    "print(\"\\nReport with leftmain_bifurcation present:\")\n",
    "display(df_merged[df_merged['mid_lad_bifurcation'] != 'Pas de lésion de bifurcation'][['Report']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization of the longest report\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load PubMedBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n",
    "# Get the longest text from the dataframe\n",
    "sample_text = df_merged.loc[df_merged['Report'].str.len().idxmax(), 'Report']\n",
    "print(\"Longest report text:\")\n",
    "print(sample_text)\n",
    "print(f\"\\nLength: {len(sample_text)} characters\")\n",
    "\n",
    "# Encode the text\n",
    "encoded = tokenizer(\n",
    "    sample_text,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Decode back to text to verify\n",
    "decoded = tokenizer.decode(encoded['input_ids'][0], skip_special_tokens=True)\n",
    "print(\"\\nDecoded text (after tokenization):\")\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bypass_graft column based on whether Conclusion contains \"pontage\" (case-insensitive)\n",
    "df_merged['bypass_graft'] = df_merged['Conclusion'].str.contains('pontage', case=False, na=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"data/reports/reports_with_alpha_separator_with_Calcifc_Stenosis_IFR_20250801_RCA_LCA_merged_with_left_dominance_dependent_vessels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = os.path.dirname(output_file_path)\n",
    "\n",
    "# Check if the directory exists, if not create it\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(f\"Initial dataframe length: {len(df_merged)}\")\n",
    "\n",
    "# Drop rows where 'External_Exam' is True\n",
    "df_merged = df_merged[df_merged[\"External_Exam\"] != True]\n",
    "print(f\"Length after dropping External_Exam: {len(df_merged)}\")\n",
    "\n",
    "df_merged = df_merged[df_merged[\"bypass_graft\"] != 1]\n",
    "print(f\"Length after dropping bypass_graft: {len(df_merged)}\")\n",
    "\n",
    "df_non_nan_reports = df_merged.dropna(subset=[\"Report\"])\n",
    "print(f\"Length after dropping NaN reports: {len(df_non_nan_reports)}\")\n",
    "\n",
    "\n",
    "# List of stenosis columns to check\n",
    "stenosis_columns = [\n",
    "    \"prox_rca_stenosis\", \"mid_rca_stenosis\", \"dist_rca_stenosis\",\n",
    "    \"left_main_stenosis\", \"prox_lad_stenosis\", \"mid_lad_stenosis\", \"dist_lad_stenosis\",\n",
    "    \"D1_stenosis\", \"D2_stenosis\", \"prox_lcx_stenosis\", \"dist_lcx_stenosis\",\n",
    "    \"om1_stenosis\", \"om2_stenosis\", \"bx_stenosis\", \"lvp_stenosis\",\n",
    "    \"pda_stenosis\", \"posterolateral_stenosis\"\n",
    "]\n",
    "\n",
    "# Create a boolean DataFrame indicating if each cell is NaN or -1.0\n",
    "is_na_or_minus_one = df_non_nan_reports[stenosis_columns].isna() | (df_non_nan_reports[stenosis_columns] == -1.0)\n",
    "\n",
    "# Create a mask for rows where NOT ALL stenosis columns are NaN or -1.0\n",
    "mask = ~is_na_or_minus_one.all(axis=1)\n",
    "\n",
    "# Filter the DataFrame to drop rows meeting the unwanted condition\n",
    "df_non_nan_reports = df_non_nan_reports[mask]\n",
    "print(f\"Final length after filtering stenosis columns: {len(df_non_nan_reports)}\")\n",
    "\n",
    "df_non_nan_reports.to_csv(output_file_path, sep=\"α\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_patient_splits(df_final, output_path, train_ratio=0.7, val_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Assigns patients to train/val/test splits and saves the resulting dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df_final (pd.DataFrame): Input dataframe containing patient data\n",
    "        output_path (str): Path where the output CSV file will be saved\n",
    "        train_ratio (float): Ratio of patients to assign to training set (default 0.7)\n",
    "        val_ratio (float): Ratio of patients to assign to validation set (default 0.15)\n",
    "        random_state (int): Random seed for reproducibility (default 42)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with train/val/test splits assigned\n",
    "    \"\"\"\n",
    "    # Split patients into train/val/test\n",
    "    unique_patients = df_final[\"CathReport_MRN\"].drop_duplicates()\n",
    "    train_size = int(train_ratio * len(unique_patients))\n",
    "    val_size = int(val_ratio * len(unique_patients))\n",
    "    \n",
    "    # Sample patients for each split\n",
    "    train_patients = unique_patients.sample(n=train_size, random_state=random_state)\n",
    "    remaining_patients = unique_patients.drop(train_patients.index)\n",
    "    val_patients = remaining_patients.sample(n=val_size, random_state=random_state)\n",
    "    test_patients = remaining_patients.drop(val_patients.index)\n",
    "\n",
    "    # Keep only the sampled patients in the dataframe\n",
    "    df_sampled = df_final[\n",
    "        df_final[\"CathReport_MRN\"].isin(train_patients) \n",
    "        | df_final[\"CathReport_MRN\"].isin(val_patients)\n",
    "        | df_final[\"CathReport_MRN\"].isin(test_patients)\n",
    "    ]\n",
    "\n",
    "    # Assign split based on CathReport_MRN\n",
    "    df_sampled.loc[df_sampled[\"CathReport_MRN\"].isin(train_patients), \"Split\"] = \"train\"\n",
    "    df_sampled.loc[df_sampled[\"CathReport_MRN\"].isin(val_patients), \"Split\"] = \"val\"\n",
    "    df_sampled.loc[df_sampled[\"CathReport_MRN\"].isin(test_patients), \"Split\"] = \"test\"\n",
    "\n",
    "    # Save the dataframe\n",
    "    df_sampled.to_csv(output_path, sep=\"α\", index=False)\n",
    "    \n",
    "    display(df_sampled.Split.value_counts())\n",
    "    return df_sampled\n",
    "\n",
    "df_sampled = assign_patient_splits(\n",
    "    df_final=df_non_nan_reports,\n",
    "    output_path=output_file_path,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique StudyInstanceUIDs per split\n",
    "split_counts = df_sampled.groupby('Split')['StudyInstanceUID'].nunique()\n",
    "display(split_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_sampled = pd.read_csv(output_file_path, sep=\"α\")\n",
    "\n",
    "display(df_sampled.object_value.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 30 unique StudyInstanceUIDs\n",
    "sampled_study_ids = df_sampled[\"StudyInstanceUID\"].unique()\n",
    "sampled_study_ids = np.random.choice(sampled_study_ids, size=30, replace=False)\n",
    "\n",
    "# Keep only rows matching the sampled StudyInstanceUIDs\n",
    "df_sampled = df_sampled[df_sampled[\"StudyInstanceUID\"].isin(sampled_study_ids)]\n",
    "display(df_sampled.Split.value_counts())\n",
    "display(df_sampled.StudyInstanceUID.value_counts())\n",
    "df_sampled.to_csv('data/reports/report_sampled_200.csv', sep='α', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "## CHANGE THIS\n",
    "dir2 = os.path.abspath(\"/volume/DicomVideoProcessing/downloadAvi\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from downloadAvi import plot_avi\n",
    "\n",
    "# Sample 2-3 random StudyInstanceUIDs\n",
    "study_ids = df_non_nan_reports.loc[df_non_nan_reports['coronary_dominance_consensus']=='right_dominant']['StudyInstanceUID'].unique()\n",
    "\n",
    "sampled_studies = np.random.choice(study_ids, size=3, replace=False)\n",
    "\n",
    "# For each sampled study, plot 8 videos\n",
    "for study_id in sampled_studies:\n",
    "    study_videos = df_non_nan_reports[df_non_nan_reports['StudyInstanceUID'] == study_id]\n",
    "    if len(study_videos) >= 3:\n",
    "        study_sample = study_videos.sample(n=9, replace=len(study_videos) < 9)\n",
    "        print(study_sample.FileName.nunique())\n",
    "        plot_avi.sample_and_plot_middle_frames(study_sample, 9, \n",
    "                                             label_column='Report', \n",
    "                                             path_column='FileName')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = pd.read_csv('data/reports/reports_with_alpha_separator_with_Calcifc_Stenosis_IFR_20250601_RCA_LCA_merged_with_left_dominance_dependent_vessels.csv', sep='α')\n",
    "df_sampled = df_sampled.loc[df_sampled[\"dominance_name\"] == \"left_dominant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load PubMedBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n",
    "# Get a sample text from the dataframe\n",
    "sample_text = df_sampled['Report'].iloc[1]\n",
    "print(sample_text)\n",
    "# Encode the text\n",
    "encoded = tokenizer(\n",
    "    sample_text,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Decode back to text to verify\n",
    "decoded = tokenizer.decode(encoded['input_ids'][0], skip_special_tokens=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
