pipeline_project: "DeepCORO_clip"
base_checkpoint_path: outputs
# Training parameters
epochs: 30
num_workers: 10
debug: false
use_amp: true
period: 2
run_mode: train
batch_size: 16
# Dataset parameters
data_filename: "output_dataset/siglip_generated/videos.csv"
root: "."
target_label: null
datapoint_loc_label: "FileName"
frames: 16
stride: 1
aggregate_videos_tokens: true
per_video_pool: false
data_mean: [105.67617, 105.67617, 105.67617]
data_std: [38.953922, 38.953922, 38.953922]
multi_video: false
num_videos: 1
groupby_column: "StudyInstanceUID"
shuffle_videos: true
siglip_texts_path: "output_dataset/siglip_generated/texts.csv"
siglip_max_positive_per_video: 15
siglip_negatives_per_video: 0
siglip_round_robin_sampling: true
siglip_max_segments_per_video: 15
siglip_positive_severity_weights:
  normal: 0.1 # Drastically reduce normal weight - don't care about matching "normal segment"
  mild: 5.0 # Mild pathology matters
  moderate: 25.0 # Moderate pathology is important
  severe: 50.0 # Severe pathology is critical to detect
  critical: 50.0 # Critical pathology is critical to detect
  cto: 50.0 # CTO is critical to detect
siglip_enable_severity_weighting: true
# Pathology-focused training: prioritize abnormal detection over normal matching
siglip_normal_as_negative: false # Set true to treat normal segments as soft negatives
siglip_positive_loss_weight: 1.0866518218782937
siglip_negative_loss_weight: 0.7860672785039889
siglip_auto_positive_loss_weight: true
# Seed
seed: 42
# Model parameters
model_name: "mvit"
pretrained: true
# Optimizer parameters
optimizer: "AdamW"
scheduler_name: "cosine_with_hard_restarts_with_warmup"
lr: 0.000008446288339329215
lr_step_period: 15
factor: 0.14617805853947136
# Multi-loss configuration
loss_name: "siglip_pairwise" # Primary loss identifier
loss_array:
  - siglip_pairwise: 1.0
  - locca_caption: 0.5
# LocCa Decoder configuration
locca_enabled: true
locca_num_layers: 4
locca_d_model: 512
locca_num_heads: 8
locca_dropout: 0.1
locca_max_seq_len: 256
tree_loss_enabled: false
tree_loss_weight: 0
video_weight_decay: 8.521396694895177e-7
text_weight_decay: 7.131150520313639e-7
gradient_accumulation_steps: 1
num_warmup_percent: 0.05
num_hard_restarts_cycles: 2
warm_restart_tmult: 1
max_grad_norm: 0.5
video_max_grad_norm: 0.25
text_max_grad_norm: 0.7
# Model architecture parameters
num_heads: 16
aggregator_depth: 2
temperature: 0.1146214999701498
dropout: 0.1115212268659706
video_freeze_ratio: 0.9227815026728848
text_freeze_ratio: 0.7417244924285019
# Checkpointing
resume_training: false
checkpoint: "outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt"
output_dir: outputs
save_best: "loss"
# Metrics
recall_k: [1, 5, 10, 50]
ndcg_k: [5]
# Data augmentation
rand_augment: true
resize: 224
apply_mask: false
# wandb parameters
tag: "mvit_pretrained_locca_pathology_focus"
name: "dev_deep_coro_clip_siglip_locca_pathology_focus"
project: "dev_deep_coro_clip_single_video"
entity: "mhi_ai"
use_wandb: true
# Inference parameters
topk: 5
text_embeddings_path: "/media/data1/datasets/ECG_Tokenizer/utils/inference/reports_embeddings.pt"
metadata_path: "/media/data1/datasets/ECG_Tokenizer/utils/inference/reports_metadata.parquet"
inference_results_path: "checkpoints/inference/"
