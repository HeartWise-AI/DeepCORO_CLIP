{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ma25bofc\n",
      "Sweep URL: https://wandb.ai/mhi_ai/My_DeepCORO_Clip_Sweep_new_hyperparam/sweeps/ma25bofc\n",
      "wandb: Agent Starting Run: k74e8m9f with config:\n",
      "\tbatch_size: 10\n",
      "\tdropout: 0.09012666452382928\n",
      "\tepochs: 40\n",
      "\tfactor: 0.3\n",
      "\tlearning_rate: 6.50906324997723e-06\n",
      "\tlr_step_period: 15\n",
      "\toptimizer: RAdam\n",
      "\tpatience: 8\n",
      "\trandom_augment: True\n",
      "\tscheduler_type: cosine\n",
      "\tstride: 1\n",
      "\ttemperature: 0.3164815794526264\n",
      "\ttext_freeze_ratio: 1\n",
      "\tvideo_freeze_ratio: 0\n",
      "{'batch_size': 10, 'learning_rate': 6.50906324997723e-06, 'epochs': 40, 'num_workers': 16, 'gpu': 1, 'model_name': 'mvit', 'optimizer': 'RAdam', 'weight_decay': 1e-06, 'scheduler_type': 'cosine', 'lr_step_period': 15, 'factor': 0.3, 'frames': 16, 'pretrained': True, 'config': 'config/default_config.yaml', 'local_rank': 0, 'debug': False, 'temperature': 0.3164815794526264, 'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': '.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'stride': 1, 'random_augment': True, 'dropout': 0.09012666452382928, 'video_freeze_ratio': 0.0, 'text_freeze_ratio': 1.0, 'use_amp': True, 'patience': 8, 'project': 'deepCORO_CLIP', 'entity': 'mhi_ai', 'tag': 'DeepCORO_Clip_Sweep_Learnable_Temp_Full', 'output_dir': 'outputs', 'multi_video': True, 'n_video': 4, 'scorn': 'StudyInstanceUID', 'aggregate_function': 'mean'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING Ignoring project 'deepCORO_CLIP' when running a sweep.\n",
      "wandb: WARNING Ignoring entity 'mhi_ai' when running a sweep.\n",
      "wandb: Currently logged in as: robertavram (mhi_ai). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.19.0\n",
      "wandb: Run data is saved locally in /volume/DeepCORO_CLIP/wandb/run-20250101_195033-k74e8m9f\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run DeepCORO_Clip_Sweep_Learnable_Temp_Full\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/mhi_ai/My_DeepCORO_Clip_Sweep_new_hyperparam\n",
      "wandb: üßπ View sweep at https://wandb.ai/mhi_ai/My_DeepCORO_Clip_Sweep_new_hyperparam/sweeps/ma25bofc\n",
      "wandb: üöÄ View run at https://wandb.ai/mhi_ai/My_DeepCORO_Clip_Sweep_new_hyperparam/runs/k74e8m9f\n",
      "wandb: WARNING Ignoring project 'deepCORO_CLIP' when running a sweep.\n",
      "wandb: WARNING Ignoring entity 'mhi_ai' when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args:  Namespace(config='config/default_config.yaml', gpu=1, batch_size=10, num_workers=16, epochs=40, learning_rate=6.50906324997723e-06, local_rank=0, debug=False, temperature=0.3164815794526264, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, random_augment=True, model_name='mvit', pretrained=True, dropout=0.09012666452382928, video_freeze_ratio=0.0, text_freeze_ratio=1.0, optimizer='RAdam', weight_decay=1e-06, scheduler_type='cosine', lr_step_period=15, factor=0.3, use_amp=True, patience=8, project='deepCORO_CLIP', entity='mhi_ai', tag='DeepCORO_Clip_Sweep_Learnable_Temp_Full', output_dir='outputs', multi_video=True, n_video=4, scorn='StudyInstanceUID', aggregate_function='mean')\n",
      "{'batch_size': 10, 'learning_rate': 6.50906324997723e-06, 'epochs': 40, 'num_workers': 16, 'gpu': 1, 'model_name': 'mvit', 'optimizer': 'RAdam', 'weight_decay': 1e-06, 'scheduler_type': 'cosine', 'lr_step_period': 15, 'factor': 0.3, 'frames': 16, 'pretrained': True, 'config': 'config/default_config.yaml', 'local_rank': 0, 'debug': False, 'temperature': 0.3164815794526264, 'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': '.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'stride': 1, 'random_augment': True, 'dropout': 0.09012666452382928, 'video_freeze_ratio': 0.0, 'text_freeze_ratio': 1.0, 'use_amp': True, 'patience': 8, 'project': 'deepCORO_CLIP', 'entity': 'mhi_ai', 'tag': 'DeepCORO_Clip_Sweep_Learnable_Temp_Full', 'output_dir': 'outputs', 'multi_video': True, 'n_video': 4, 'scorn': 'StudyInstanceUID', 'aggregate_function': 'mean'}\n",
      "Args:  Namespace(config='config/default_config.yaml', gpu=1, batch_size=10, num_workers=16, epochs=40, learning_rate=6.50906324997723e-06, local_rank=0, debug=False, temperature=0.3164815794526264, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, random_augment=True, model_name='mvit', pretrained=True, dropout=0.09012666452382928, video_freeze_ratio=0, text_freeze_ratio=1, optimizer='RAdam', weight_decay=1e-06, scheduler_type='cosine', lr_step_period=15, factor=0.3, use_amp=True, patience=8, project='deepCORO_CLIP', entity='mhi_ai', tag='DeepCORO_Clip_Sweep_Learnable_Temp_Full', output_dir='outputs', multi_video=True, n_video=4, scorn='StudyInstanceUID', aggregate_function='mean')\n",
      "\n",
      "=== Calculating Dataset Statistics ===\n",
      "Stats dataset length: 128\n",
      "\n",
      "Using 100 samples for statistics calculation\n",
      "Frame count per video: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating statistics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Mean: [102.05670928955078, 102.05670928955078, 102.05670928955078]\n",
      "Std:  [39.183250427246094, 39.183250427246094, 39.183250427246094]\n",
      "Calculated from 100 samples (80,281,600 pixels)\n",
      "===========================\n",
      "\n",
      "Using MultiVideoDataset with aggregator: mean\n",
      "[MultiVideoDataset] Found 31286 studies in split='train'\n",
      "[MultiVideoDataset] Found 3463 studies in split='val'\n",
      "\n",
      "=== Dataset Information ===\n",
      "Training:   31,286 videos (or studies if multi-video)\n",
      "Validation: 3,463 videos (or studies if multi-video)\n",
      "Total:      34,749\n",
      "\n",
      "Batch Size: 10\n",
      "Training Batches: 3,128\n",
      "Validation Batches: 347\n",
      "===========================\n",
      "\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3128/3128 [1:23:02<00:00,  1.59s/it, train_loss=2.1958, avg_train_loss=2.2577]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch=0, Loss=2.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [09:15<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Validate] Epoch=0, Loss=2.1755\n",
      "Avg Text Embedding (first 5 dims): tensor([0.0036, 0.1089, 0.0649, 0.0114, 0.0144], device='cuda:0')\n",
      "Saved checkpoint to outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b10_f16_RAdam_lr6.50906324997723e-06_20250101-195034_k74e8m9f/checkpoints/latest.pt\n",
      "\n",
      "Saved latest checkpoint at epoch 1\n",
      "Saved checkpoint to outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b10_f16_RAdam_lr6.50906324997723e-06_20250101-195034_k74e8m9f/checkpoints/best.pt\n",
      "\n",
      "New best model saved! Val Loss (val-only): 2.1755 (previous: inf)\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3128/3128 [1:12:10<00:00,  1.38s/it, train_loss=2.1902, avg_train_loss=2.1714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch=1, Loss=2.1714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [08:22<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Validate] Epoch=1, Loss=2.1268\n",
      "Avg Text Embedding (first 5 dims): tensor([0.0040, 0.0847, 0.0312, 0.0090, 0.0035], device='cuda:0')\n",
      "Saved checkpoint to outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b10_f16_RAdam_lr6.50906324997723e-06_20250101-195034_k74e8m9f/checkpoints/latest.pt\n",
      "\n",
      "Saved latest checkpoint at epoch 2\n",
      "Saved checkpoint to outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b10_f16_RAdam_lr6.50906324997723e-06_20250101-195034_k74e8m9f/checkpoints/best.pt\n",
      "\n",
      "New best model saved! Val Loss (val-only): 2.1268 (previous: 2.1755)\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3128/3128 [1:13:19<00:00,  1.41s/it, train_loss=2.2033, avg_train_loss=2.1416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch=2, Loss=2.1416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [08:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Validate] Epoch=2, Loss=2.0918\n",
      "Avg Text Embedding (first 5 dims): tensor([0.0004, 0.0762, 0.0006, 0.0190, 0.0001], device='cuda:0')\n",
      "Saved checkpoint to outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b10_f16_RAdam_lr6.50906324997723e-06_20250101-195034_k74e8m9f/checkpoints/latest.pt\n",
      "\n",
      "Saved latest checkpoint at epoch 3\n",
      "Saved checkpoint to outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b10_f16_RAdam_lr6.50906324997723e-06_20250101-195034_k74e8m9f/checkpoints/best.pt\n",
      "\n",
      "New best model saved! Val Loss (val-only): 2.0918 (previous: 2.1268)\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  15%|‚ñà‚ñå        | 471/3128 [10:43<36:09,  1.22it/s, train_loss=2.1513, avg_train_loss=2.1142]  "
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "def load_yaml_config(file_path):\n",
    "    with open(file_path) as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "sweep_conf_file_path = \"config/sweep_config.yaml\"\n",
    "sweep_conf = load_yaml_config(sweep_conf_file_path)\n",
    "count = 25  # number of runs to execute\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_conf, project=sweep_conf[\"name\"], entity=\"mhi_ai\")\n",
    "\n",
    "wandb.agent(sweep_id=sweep_id, entity=\"mhi_ai\", project=sweep_conf[\"name\"], count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.logging import cleanup_temp_video, convert_video_for_wandb\n",
    "\n",
    "# Read the CSV file containing sampled reports\n",
    "reports_df = pd.read_csv(\"data/reports/reports_sampled_no_conclusion_1000.csv\", sep=\"Œ±\")\n",
    "print(f\"Loaded {len(reports_df)} reports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reports_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(\u001b[43mreports_df\u001b[49m\u001b[38;5;241m.\u001b[39mFileName)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reports_df' is not defined"
     ]
    }
   ],
   "source": [
    "display(reports_df.FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first video path\n",
    "video_path = reports_df.FileName.iloc[0]\n",
    "\n",
    "# Convert video to wandb format\n",
    "mp4_path, is_temp = convert_video_for_wandb(video_path)\n",
    "\n",
    "print(f\"Converted video path: {mp4_path}\")\n",
    "print(f\"Is temporary file: {is_temp}\")\n",
    "\n",
    "# Clean up temp file if needed\n",
    "if is_temp:\n",
    "    cleanup_temp_video(mp4_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
