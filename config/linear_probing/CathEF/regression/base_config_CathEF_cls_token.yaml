# Improved CLS Token Configuration for CathEF Regression
# Showcases advanced features: separate attention layers, hybrid pooling, configurable heads

# Pipeline parameters
pipeline_project: !!str DeepCORO_video_linear_probing
base_checkpoint_path: !!str outputs
run_mode: !!str train
epochs: !!int 25
seed: !!int 42

# wandb parameters
name: !!str DeepCORO_video_linear_probing_cathEF_improved_cls_token
project: !!str DeepCORO_video_linear_probing_cathEF_improved_cls_token
entity: !!str mhi_ai
use_wandb: !!bool true

# Training parameters
scheduler_name: !!str cosine_with_warmup
num_warmup_percent: !!float 0.08
optimizer: !!str AdamW
use_amp: !!bool true
gradient_accumulation_steps: !!int 1

# Scheduler parameters
lr_step_period: !!int 10
factor: !!float 0.1
num_hard_restarts_cycles: !!int 3
warm_restart_tmult: !!float 2.0

# Dataset parameters
data_filename: !!str data/reports/CathEF_MHI_UCSF_2016-to-july-2022-and-2023-08-30-post-CathEF_alpha_StudyInstanceUID_updated.csv
num_workers: !!int 8
batch_size: !!int 8  # Smaller due to hybrid pooling memory requirements
multi_video: !!bool true
groupby_column: !!str 'StudyInstanceUID'
num_videos: !!int 4
shuffle_videos: !!bool true
datapoint_loc_label: !!str FileName
target_label: [Value, y_true_cat]
rand_augment: !!bool true
resize: !!int 224
frames: !!int 16
stride: !!int 2

# Improved CLS Token Configuration
pooling_mode: !!str attention+cls_token  # Hybrid pooling for richer features
separate_video_attention: !!bool true    # Separate within/across-video attention
num_attention_heads: !!int 8             # Configurable attention heads
normalization_strategy: !!str post_norm  # Post-norm like ViT (can try pre_norm)
use_cls_token: !!bool true

# Video Encoder parameters
model_name: !!str mvit
aggregator_depth: !!int 2
num_heads: !!int 4
video_freeze_ratio: !!float 0.9179658719319556
dropout: !!float 0.15
pretrained: !!bool true

# Learning rates - Optimized for improved architecture
video_encoder_lr: !!float 8.795617632783049e-06  # Conservative for pretrained
video_encoder_weight_decay: !!float 1.8160563690364244e-06

# Attention learning rates - separate for within/across attention
attention_within_lr: !!float 2e-3        # Within-video attention
attention_across_lr: !!float 1.5e-3      # Across-video attention  
attention_weight_decay: !!float 5e-5

# Hybrid pooling means 2x feature dimension, so lower LR
head_lr: !!float 3e-4                    # Lower due to 2x input features
head_weight_decay: !!float 1e-5

video_encoder_checkpoint_path: !!str outputs/DeepCORO_clip/DeepCORO_Clip_Sweep_Multi_Video/mhduqrk9_20250520-160616/outputs/DeepCORO_clip/DeepCORO_Clip_Sweep_Multi_Video/mhduqrk9_20250520-160846_best_MVIT/checkpoints/highest_alignment_epoch_24.pt

aggregate_videos_tokens: !!bool false   # Maintain 4D structure for hierarchical processing
per_video_pool: !!bool false            # Let improved cls_token handle all pooling
output_dir: !!str outputs/

# Enhanced Linear Probing parameters
head_linear_probing: # Use improved linear probing classes
  Value: !!str cls_token_linear_probing_regression
  y_true_cat: !!str cls_token_linear_probing

head_structure: # Note: Input will be 2x embedding_dim due to hybrid pooling
  Value: !!int 1
  y_true_cat: !!int 1

head_dropout: # Higher dropout due to richer features
  Value: !!float 0.2
  y_true_cat: !!float 0.2

loss_structure:
  Value: !!str mae
  y_true_cat: !!str bce_logit

head_lr: # Lower LR for hybrid features
  Value: !!float 3e-4
  y_true_cat: !!float 3e-4

head_weight_decay:
  Value: !!float 1e-5
  y_true_cat: !!float 1e-5

head_weights:
  Value: !!float 1.0
  y_true_cat: !!float 1.0

head_task:
  Value: !!str regression
  y_true_cat: !!str classification

# Label mappings
labels_map:
  Value:
    Value: !!str regression
  y_true_cat:
    y_true_cat: !!str EF

# Advanced Configuration Notes
notes: |
  Improved CLS Token Configuration with Advanced Features:
  
  üöÄ New Features Enabled:
  ‚Ä¢ Hybrid Pooling: attention+cls_token provides 2x richer feature representations
  ‚Ä¢ Separate Attention: Different layers for within-video and across-video attention
  ‚Ä¢ Configurable Heads: 8 attention heads for better representational capacity
  ‚Ä¢ Post-Norm Strategy: Layer normalization after attention (ViT-style)
  ‚Ä¢ Enhanced Edge Handling: Robust fallbacks for empty masks
  
  üß† Architecture Benefits:
  ‚Ä¢ More sophisticated attention patterns for complex medical video analysis
  ‚Ä¢ Better capture of both local (within-video) and global (across-video) relationships
  ‚Ä¢ Richer feature representations through hybrid pooling
  ‚Ä¢ Improved training stability with separate learning rates
  
  ‚öôÔ∏è Training Optimizations:
  ‚Ä¢ Separate learning rates for within/across-video attention components
  ‚Ä¢ Lower learning rates compensating for 2x feature dimensions
  ‚Ä¢ Conservative video encoder updates to preserve pretrained knowledge
  ‚Ä¢ Higher dropout to prevent overfitting with richer features
  
  üíæ Memory Considerations:
  ‚Ä¢ Smaller batch size due to hybrid pooling memory requirements
  ‚Ä¢ 2x feature dimensions in classification heads
  ‚Ä¢ Separate attention layers increase parameter count
  
  Expected Performance: Significant improvement over standard pooling methods
  due to learnable, task-adaptive attention patterns and richer feature representations. 