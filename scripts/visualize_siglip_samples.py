#!/usr/bin/env python3
"""Visualize SigLIP video/text samples.

Usage:
    python scripts/visualize_siglip_samples.py \
        --videos datasets/siglip_multiprompt_output/videos.csv \
        --texts datasets/siglip_multiprompt_output/texts.csv \
        --edges datasets/siglip_multiprompt_output/edges.csv \
        --num-samples 3 \
        --frames-per-video 5 \
        --output outputs/debug_frames

The script loads the manifests generated by `generate_siglip_category_dataset.py`,
selects a handful of video IDs (either user-specified or sampled from the top of the
CSV), extracts a representative prompt for each, and saves a figure containing the
middle frames with the prompt caption.
"""

from __future__ import annotations

import argparse
import os
from pathlib import Path
import textwrap
from typing import Iterable, List, Optional

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Visualize SigLIP video/prompt pairs")
    parser.add_argument("--videos", required=True, help="Path to videos.csv")
    parser.add_argument("--texts", required=True, help="Path to texts.csv")
    parser.add_argument("--edges", required=True, help="Path to edges.csv")
    parser.add_argument(
        "--video-ids",
        nargs="*",
        default=None,
        help="Optional list of video IDs to visualize.",
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=3,
        help="Number of samples to visualize when --video-ids is not provided.",
    )
    parser.add_argument(
        "--frames-per-video",
        type=int,
        default=5,
        help="Number of frames to sample around the middle of each video.",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="outputs/debug_frames",
        help="Directory where figures will be saved.",
    )
    return parser.parse_args()


def select_video_ids(
    videos_df: pd.DataFrame,
    requested_ids: Optional[Iterable[str]],
    num_samples: int,
) -> List[str]:
    if requested_ids:
        valid = [vid for vid in requested_ids if vid in set(videos_df["video_id"])]
        missing = set(requested_ids) - set(valid)
        if missing:
            print(f"[WARN] Skipping unknown video IDs: {sorted(missing)}")
        if valid:
            return valid
    return list(videos_df["video_id"].head(num_samples))


def pick_prompt(
    video_id: str,
    edges_df: pd.DataFrame,
    texts_df: pd.DataFrame,
) -> str:
    matches = edges_df[edges_df["video_id"] == video_id]
    if matches.empty:
        return "<no positive prompt found>"
    text_id = matches.iloc[0]["text_id"]
    row = texts_df[texts_df["text_id"] == text_id]
    if row.empty:
        return "<text missing>"
    prompt = row.iloc[0]["prompt_text"]
    return str(prompt)


def extract_frames(
    video_path: Path,
    frames_per_video: int,
) -> List[np.ndarray]:
    if not video_path.exists():
        raise FileNotFoundError(f"Video file not found: {video_path}")

    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"Failed to open video: {video_path}")

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if frame_count <= 0:
        cap.release()
        raise RuntimeError(f"Unable to read frame count for: {video_path}")

    mid = frame_count // 2
    half = max(frames_per_video // 2, 1)
    start = max(0, mid - half)
    indices = [min(frame_count - 1, start + i) for i in range(frames_per_video)]

    frames: List[np.ndarray] = []
    for idx in indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ok, frame = cap.read()
        if not ok:
            continue
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame_rgb)

    cap.release()
    return frames


def save_figure(
    video_id: str,
    video_path: Path,
    prompt: str,
    frames: List[np.ndarray],
    output_dir: Path,
):
    if not frames:
        print(f"[WARN] No frames extracted for {video_path}; skipping visualization")
        return

    output_dir.mkdir(parents=True, exist_ok=True)
    cols = len(frames)
    fig, axes = plt.subplots(1, cols, figsize=(cols * 3.5, 3.5))
    if cols == 1:
        axes = [axes]

    for ax, frame in zip(axes, frames):
        ax.imshow(frame)
        ax.axis("off")

    wrapped_prompt = "\n".join(textwrap.wrap(prompt, width=80))
    title = f"{video_id}\n{video_path.name}"
    fig.suptitle(f"{title}\nPrompt: {wrapped_prompt}", fontsize=10)
    fig.tight_layout()

    safe_name = f"{video_id}_frames.png"
    output_path = output_dir / safe_name
    fig.savefig(output_path, dpi=150)
    plt.close(fig)
    print(f"[INFO] Saved {output_path}")


def main():
    args = parse_args()
    videos_df = pd.read_csv(args.videos)
    texts_df = pd.read_csv(args.texts)
    edges_df = pd.read_csv(args.edges)

    video_ids = select_video_ids(videos_df, args.video_ids, args.num_samples)
    output_dir = Path(args.output)

    for vid in video_ids:
        row = videos_df[videos_df["video_id"] == vid]
        if row.empty:
            print(f"[WARN] video_id {vid} missing from manifest; skipping")
            continue
        video_path = Path(str(row.iloc[0]["FileName"])).expanduser()
        prompt = pick_prompt(vid, edges_df, texts_df)
        try:
            frames = extract_frames(video_path, args.frames_per_video)
        except Exception as exc:
            print(f"[ERROR] {exc}")
            continue
        save_figure(vid, video_path, prompt, frames, output_dir)


if __name__ == "__main__":
    main()
