pipeline_project: !!str "DeepCORO_multitask"
base_checkpoint_path: !!str outputs
# Training parameters
epochs: !!int 10
num_workers: !!int 8
debug: !!bool false
use_amp: !!bool true
period: !!int 1
run_mode: !!str train
# Dataset parameters
data_filename: !!str /media/data1/ravram/DeepCORO_CLIP_ENCODER/datasets/reports_with_alpha_separator_with_Calcifc_Stenosis_IFR_20250601_RCA_LCA_merged_with_left_dominance_dependent_vessels.csv
root: !!str "."
target_label: !!str Report
datapoint_loc_label: !!str FileName
frames: !!int 16
stride: !!int 3
aggregate_videos_tokens: !!bool false # We need token-level features for captioning
per_video_pool: !!bool false
multi_video: !!bool false
num_videos: !!int 1
groupby_column: !!str StudyInstanceUID
shuffle_videos: !!bool true
batch_size: !!int 20
# Seed
seed: !!int 42
# Model parameters
model_name: !!str mvit
pretrained: !!bool true # mvit_rope loads from checkpoint instead
# Encoder checkpoint loading (for mvit_rope)
#16_2_AdamW_new_20250922-140829_dlgtqw29/best.pt
# RoPE parameters (automatically enabled for mvit_rope)
use_rope: !!bool false
rope_base: !!float 10000.0
rope_temporal_scale: !!float 1.0
rope_normalize_mode: !!str separate
# Optimizer parameters
optimizer: !!str AdamW
scheduler_name: !!str cosine
lr: !!float 0.00007165816333695567
lr_step_period: !!int 20
factor: !!float 0.4476789624289505
video_weight_decay: !!float 0.0000012452296627045836
text_weight_decay: !!float 0.0000023788202208800953
gradient_accumulation_steps: !!int 2
num_warmup_percent: !!float 0.11395879116969788
num_hard_restarts_cycles: !!float 1.0
warm_restart_tmult: !!int 2
max_grad_norm: !!float 1.0  # Match CLIP's value for stable training
# Model architecture parameters 
num_heads: !!int 8
aggregator_depth: !!int 2
# Temperature (stored in config as actual temp, converted to log-space in code)
# CLIP convention: init at ~0.07-0.1 for sharp contrastive learning
# Using CLIP-style temperature since we need strong alignment signal
temperature: !!float 0.1  # Will be converted to log-space: log(0.1) ≈ -2.303
dropout: !!float 0.04928288833463287
video_freeze_ratio: !!float 0.8
text_freeze_ratio: !!float 0.9
# Captioning decoder parameters
vocab_size: !!int 30522
decoder_layers: !!int 6
decoder_heads: !!int 8
decoder_intermediate_size: !!int 1024
max_position_embeddings: !!int 512
use_biomed_tokenizer: !!bool true
max_text_length: !!int 512
max_generation_length: !!int 64
captioning_do_sample: !!bool false
captioning_temperature: !!float 1.0
# Masked video modeling parameters
mvm_decoder_hidden_size: !!int 128
mvm_decoder_layers: !!int 3
mvm_decoder_heads: !!int 4
mask_ratio: !!float 0.7656336791246914
mask_token_learnable: !!bool true
norm_predict_loss: !!bool true
# Learning rates for different components
text_lr: !!float 0.00002
captioning_lr: !!float 0.0001     # Captioning decoder LR (4x increase)
captioning_weight_decay: !!float 0.01
mvm_lr: !!float 0.00003           # MVM LR (increased 2x)
mvm_weight_decay: !!float 0.00762233358781642
# Loss configuration
loss_name: !!str multitask
contrastive_loss_type: !!str siglip
captioning_loss_type: !!str cross_entropy
masked_modeling_loss_type: !!str mse
label_smoothing: !!float 0.07940141273202601
ignore_index: !!int -100
# Loss weights (CONTRASTIVE DOMINANT - match CLIP philosophy)
# Contrastive must dominate for proper alignment learning
# Captioning and MVM are auxiliary tasks that enhance, not compete
loss_weights:
  contrastive: !!float 2.0      # DOMINANT - primary objective
  captioning: !!float 0.3        # AUXILIARY - supports alignment
  masked_modeling: !!float 0.1   # REGULARIZATION - weak signal
  distillation: !!float 0.0
  stenosis_mse: !!float 0.3      # Per-artery stenosis percentage MSE
  critical_bce: !!float 0.2      # Critical finding detection (≥70%)
# Patch-level contrastive weight (DISABLED - creates gradient interference)
# Setting to 0 eliminates conflicting contrastive objectives
patch_contrastive_weight: !!float 0.0
# Stenosis-aware loss configuration
use_stenosis_loss: !!bool true
stenosis_mse_weight: !!float 0.3     # Weight for per-artery stenosis MSE
critical_bce_weight: !!float 0.2     # Weight for critical finding detection
critical_threshold: !!float 70.0     # Threshold for critical stenosis (%)
numeric_token_weight_multiplier: !!float 5.0  # Future: upweight numeric tokens
# Loss weight scheduler (optional)
use_loss_weight_scheduler: !!bool false
initial_loss_weights:
  contrastive: !!float 0.5
  captioning: !!float 0.5
  masked_modeling: !!float 0.1
final_loss_weights:
  contrastive: !!float 0.5
  captioning: !!float 0.5
  masked_modeling: !!float 0.1
loss_warmup_steps: !!int 1000
loss_total_steps: !!int 10000
loss_schedule_type: !!str linear # "linear", "cosine", "step"
# Video pooling configuration (used by video encoder)
video_pooling_mode: !!str cls_token # "mean", "attention", or "cls_token"
attention_pool_heads: !!int 8
attention_pool_dropout: !!float 0.1
use_cls_token: !!bool true
# Checkpointing
resume_training: !!bool false
checkpoint: !!str ""
output_dir: !!str outputs
save_best: !!str loss
# Metrics
# Recall @k
recall_k: [1, 5, 10, 50]
# NDCG @k
ndcg_k: [5]
# Data augmentation
rand_augment: !!bool true
resize: !!int 224
apply_mask: !!bool false
# wandb parameters
tag: !!str mvit_multitask
name: !!str DeepCORO_Multitask_Training
project: !!str DeepCORO_Multitask
entity: !!str mhi_ai
use_wandb: !!bool true
# Inference parameters
topk: !!int 5
text_embeddings_path: !!str /media/data1/datasets/ECG_Tokenizer/utils/inference/reports_embeddings.pt
metadata_path: !!str /media/data1/datasets/ECG_Tokenizer/utils/inference/reports_metadata.parquet
inference_results_path: !!str checkpoints/inference/
