name: 'DeepCORO_Multitask_Sweep_MVIT2S_ROPE'
project: 'DeepCORO_Multitask'
entity: 'mhi_ai'
method: bayes
metric:
  goal: minimize
  name: val/total_loss

parameters:
  # Core contrastive learning parameters (based on working config)
  epochs:
    value: 10

  lr:
    distribution: log_uniform_values
    min: 0.00005
    max: 0.0002

  text_lr:
    distribution: log_uniform_values
    min: 0.00005
    max: 0.0002

  # Temperature for contrastive learning (CLIP-style sharp distribution)
  # CLIP uses temp â‰ˆ 0.07-0.15 for strong alignment signal
  # Sharp temperature = strong gradients = better contrastive learning
  temperature_start:
    distribution: uniform
    min: 0.07
    max: 0.15

  temperature_end:
    distribution: uniform
    min: 0.07
    max: 0.15

  temperature_schedule:
    values: ["constant", "linear"]

  # Freeze ratios (reduced to allow encoder adaptation without destroying features)
  video_freeze_ratio:
    distribution: uniform
    min: 0.7
    max: 0.9

  text_freeze_ratio:
    distribution: uniform
    min: 0.8  
    max: 0.9


  # Aggregation parameters
  aggregator_depth:
    values: [1, 2]

  attention_pool_heads:
    values: [8, 16]

  attention_pool_dropout:
    distribution: uniform
    min: 0.05
    max: 0.15

  # Video pooling configuration
  use_cls_token:
    values: [true, false]

  video_pooling_mode:
    values: ["cls_token", "attention"]

  # Auxiliary task learning rates (increased for captioning to match higher loss weight)
  captioning_lr:
    distribution: log_uniform_values
    min: 0.00005
    max: 0.0002

  mvm_lr:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.00005

  # Weight decay
  video_weight_decay:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.0001

  text_weight_decay:
    distribution: log_uniform_values
    min: 0.000001
    max: 0.00001

  captioning_weight_decay:
    distribution: uniform
    min: 0.01
    max: 0.05

  mvm_weight_decay:
    distribution: uniform
    min: 0.01
    max: 0.05

  # Loss weights (CONTRASTIVE DOMINANT - match CLIP philosophy)
  # Contrastive must be primary objective for proper alignment
  loss_weights.contrastive:
    distribution: uniform
    min: 1.5
    max: 3.0

  loss_weights.captioning:
    distribution: uniform
    min: 0.2
    max: 0.5

  loss_weights.masked_modeling:
    distribution: uniform
    min: 0.05
    max: 0.2

  # Patch-level contrastive weight (DISABLED - creates gradient interference)
  # Do not sweep - always 0 to eliminate conflicting objectives
  # patch_contrastive_weight: 0.0  (removed from sweep)

  # Lightweight auxiliary task architectures
  decoder_layers:
    values: [4, 6]

  decoder_heads:
    values: [4, 8]

  decoder_intermediate_size:
    values: [1024, 2048]

  max_generation_length:
    value: 256

  mvm_decoder_hidden_size:
    values: [128, 256]

  mvm_decoder_layers:
    values: [1, 2]

  mvm_decoder_heads:
    values: [4, 8]

  mask_ratio:
    distribution: uniform
    min: 0.6
    max: 0.8

  # Training parameters
  batch_size:
    values: [16, 20]

  gradient_accumulation_steps:
    values: [1, 2]

  num_warmup_percent:
    distribution: uniform
    min: 0.1
    max: 0.2

  label_smoothing:
    distribution: uniform
    min: 0.0
    max: 0.1

  # Data parameters
  frames:
    value: 16

  stride:
    values: [1, 2]

  # Scheduler (cosine with hard restarts worked well)
  scheduler_name:
    values: ["cosine_with_warmup", "cosine_with_hard_restarts_with_warmup"]

  num_hard_restarts_cycles:
    values: [1, 2]


command:
  - python
  - -m
  - torch.distributed.run
  - --nproc_per_node=2
  - --master_port=29500
  - scripts/main.py
  - --base_config
  - "config/clip/multitask_config.yaml"