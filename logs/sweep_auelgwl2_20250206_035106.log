Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_300_study_ids.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=True, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=0.0006150673437909941, optimizer='AdamW', scheduler_type='cosine', lr_step_period=15, factor=0.4534350375551728, video_weight_decay=1.381236674580438e-07, text_weight_decay=8.595483973855032e-07, loss_name='contrastive', temperature=0.08561015072200368, dropout=0.29014360219322877, video_freeze_ratio=0.7931173734789172, text_freeze_ratio=0.9229025166211364, num_heads=2, aggregator_depth=3, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.0006150673437909941, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.08561015072200368, data_filename='data/reports/reports_sampled_300_study_ids.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=True, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.7931173734789172, text_freeze_ratio=0.9229025166211364, dropout=0.29014360219322877, num_heads=2, aggregator_depth=3, optimizer='AdamW', scheduler_type='cosine', lr_step_period=15, factor=0.4534350375551728, video_weight_decay=1.381236674580438e-07, text_weight_decay=8.595483973855032e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_300_study_ids.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=True, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=0.0006150673437909941, optimizer='AdamW', scheduler_type='cosine', lr_step_period=15, factor=0.4534350375551728, video_weight_decay=1.381236674580438e-07, text_weight_decay=8.595483973855032e-07, loss_name='contrastive', temperature=0.08561015072200368, dropout=0.29014360219322877, video_freeze_ratio=0.7931173734789172, text_freeze_ratio=0.9229025166211364, num_heads=2, aggregator_depth=3, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.0006150673437909941, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.08561015072200368, data_filename='data/reports/reports_sampled_300_study_ids.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=True, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.7931173734789172, text_freeze_ratio=0.9229025166211364, dropout=0.29014360219322877, num_heads=2, aggregator_depth=3, optimizer='AdamW', scheduler_type='cosine', lr_step_period=15, factor=0.4534350375551728, video_weight_decay=1.381236674580438e-07, text_weight_decay=8.595483973855032e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 1
("Config: {'lr': 0.0006150673437909941, 'batch_size': 10, 'epochs': 20, "
 "'num_workers': 16, 'debug': False, 'temperature': 0.08561015072200368, "
 "'data_filename': 'data/reports/reports_sampled_300_study_ids.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 2, 'multi_video': True, 'num_videos': 4, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.7931173734789172, "
 "'text_freeze_ratio': 0.9229025166211364, 'dropout': 0.29014360219322877, "
 "'num_heads': 2, 'aggregator_depth': 3, 'optimizer': 'AdamW', "
 "'scheduler_type': 'cosine', 'lr_step_period': 15, 'factor': "
 "0.4534350375551728, 'video_weight_decay': 1.381236674580438e-07, "
 "'text_weight_decay': 8.595483973855032e-07, 'output_dir': 'outputs', 'seed': "
 "42, 'use_amp': True, 'device': 'cuda', 'period': 1, 'loss_name': "
 "'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], 'rand_augment': True, "
 "'resize': 224, 'apply_mask': False, 'view_count': None, 'save_best': 'loss', "
 "'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")
f0a85bca3128:114053:114053 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:114053:114053 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:114053:114053 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:114053:114053 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:114053:114053 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:114054:114054 [1] NCCL INFO cudaDriverVersion 12040
f0a85bca3128:114054:114054 [1] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:114054:114054 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:114054:114054 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:114054:114054 [1] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:114054:114127 [1] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:114054:114127 [1] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:114054:114127 [1] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:114054:114127 [1] NCCL INFO Using network Socket
f0a85bca3128:114053:114126 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:114053:114126 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:114053:114126 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:114053:114126 [0] NCCL INFO Using network Socket
f0a85bca3128:114054:114127 [1] NCCL INFO ncclCommInitRank comm 0x55fe72813500 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 25000 commId 0x7a6f13ce9df1db04 - Init START
f0a85bca3128:114053:114126 [0] NCCL INFO ncclCommInitRank comm 0x55af1c75a690 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 1000 commId 0x7a6f13ce9df1db04 - Init START
f0a85bca3128:114054:114127 [1] NCCL INFO Setting affinity for GPU 1 to ff0000,00000000,00ff0000
f0a85bca3128:114053:114126 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:114053:114126 [0] NCCL INFO comm 0x55af1c75a690 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
f0a85bca3128:114054:114127 [1] NCCL INFO comm 0x55fe72813500 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
f0a85bca3128:114053:114126 [0] NCCL INFO Channel 00/02 :    0   1
f0a85bca3128:114053:114126 [0] NCCL INFO Channel 01/02 :    0   1
f0a85bca3128:114053:114126 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
f0a85bca3128:114053:114126 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:114054:114127 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
f0a85bca3128:114054:114127 [1] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:114053:114126 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
f0a85bca3128:114053:114126 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
f0a85bca3128:114054:114127 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
f0a85bca3128:114054:114127 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
f0a85bca3128:114053:114126 [0] NCCL INFO Connected all rings
f0a85bca3128:114053:114126 [0] NCCL INFO Connected all trees
f0a85bca3128:114053:114126 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
f0a85bca3128:114053:114126 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f0a85bca3128:114054:114127 [1] NCCL INFO Connected all rings
f0a85bca3128:114054:114127 [1] NCCL INFO Connected all trees
f0a85bca3128:114054:114127 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
f0a85bca3128:114054:114127 [1] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f0a85bca3128:114053:114126 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:114053:114126 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:114053:114126 [0] NCCL INFO ncclCommInitRank comm 0x55af1c75a690 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 1000 commId 0x7a6f13ce9df1db04 - Init COMPLETE
f0a85bca3128:114054:114127 [1] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:114054:114127 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:114054:114127 [1] NCCL INFO ncclCommInitRank comm 0x55fe72813500 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 25000 commId 0x7a6f13ce9df1db04 - Init COMPLETE

=== Calculating Dataset Statistics ===
Frame count per video: 16

Dataset Statistics:
Mean: [114.5306625366211, 114.5306625366211, 114.5306625366211]
Std:  [36.459014892578125, 36.459014892578125, 36.459014892578125]
===========================

Rank: 0 - mean: tensor([114.5307, 114.5307, 114.5307]) - std: tensor([36.4590, 36.4590, 36.4590])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[114.5306625366211, 114.5306625366211, 114.5306625366211]
[MultiVideoDataset] std=[36.459014892578125, 36.459014892578125, 36.459014892578125]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
Rank: 1 - mean: tensor([114.5307, 114.5307, 114.5307]) - std: tensor([36.4590, 36.4590, 36.4590])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[114.5306625366211, 114.5306625366211, 114.5306625366211]
[MultiVideoDataset] std=[36.459014892578125, 36.459014892578125, 36.459014892578125]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 273 studies in split='train'[MultiVideoDataset] Found 273 studies in split='train'

[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[114.5306625366211, 114.5306625366211, 114.5306625366211]
[MultiVideoDataset] std=[36.459014892578125, 36.459014892578125, 36.459014892578125]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[114.5306625366211, 114.5306625366211, 114.5306625366211]
[MultiVideoDataset] std=[36.459014892578125, 36.459014892578125, 36.459014892578125]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 27 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'
[MultiVideoDataset] Found 27 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   13 batches per GPU
Validation: 2 batches per GPU
Total:      15 batches per GPU

Batch Size: 10
Training: 130 videos per GPU
Validation: 20 videos per GPU
Total: 150 videos per GPU
===========================

Saved 27 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/val_texts.csv
[DEBUG rank=0] local_video_feats=torch.Size([130, 512]), local_text_feats=torch.Size([130, 512]), mode=train
[DEBUG] rank=0 => Logged train metrics to W&B
[DEBUG rank=0] local_video_feats=torch.Size([14, 512]), local_text_feats=torch.Size([14, 512]), mode=val
[DEBUG rank=0] Starting NxN sim matrix with 28 items.
[DEBUG rank=0] NxN sim matrix done. shape=torch.Size([28, 28])
[DEBUG rank=0] Completed retrieval metrics & logging for val at epoch=0
[DEBUG] rank=0 => Logged val metrics to W&B

New best model! Val Loss: 2.5387 (previous: inf)

Saved best checkpoint at epoch 1 to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/checkpoints/best_epoch.pt

Saved latest checkpoint at epoch 1 to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/checkpoints/checkpoint.pt
[DEBUG rank=0] local_video_feats=torch.Size([130, 512]), local_text_feats=torch.Size([130, 512]), mode=train
[DEBUG] rank=0 => Logged train metrics to W&B
[DEBUG rank=0] local_video_feats=torch.Size([14, 512]), local_text_feats=torch.Size([14, 512]), mode=val
[DEBUG rank=0] Starting NxN sim matrix with 28 items.
[DEBUG rank=0] NxN sim matrix done. shape=torch.Size([28, 28])
[DEBUG rank=0] Completed retrieval metrics & logging for val at epoch=1
[DEBUG] rank=0 => Logged val metrics to W&B

Saved latest checkpoint at epoch 2 to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/checkpoints/checkpoint.pt
[DEBUG rank=0] local_video_feats=torch.Size([130, 512]), local_text_feats=torch.Size([130, 512]), mode=train
[DEBUG] rank=0 => Logged train metrics to W&B
[DEBUG rank=0] local_video_feats=torch.Size([14, 512]), local_text_feats=torch.Size([14, 512]), mode=val
[DEBUG rank=0] Starting NxN sim matrix with 28 items.
[DEBUG rank=0] NxN sim matrix done. shape=torch.Size([28, 28])
[DEBUG rank=0] Completed retrieval metrics & logging for val at epoch=2
[DEBUG] rank=0 => Logged val metrics to W&B

New best model! Val Loss: 2.5377 (previous: 2.5387)

Saved best checkpoint at epoch 3 to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/checkpoints/best_epoch.pt

Saved latest checkpoint at epoch 3 to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/checkpoints/checkpoint.pt
[DEBUG rank=0] local_video_feats=torch.Size([130, 512]), local_text_feats=torch.Size([130, 512]), mode=train
[DEBUG] rank=0 => Logged train metrics to W&B
[DEBUG rank=0] local_video_feats=torch.Size([14, 512]), local_text_feats=torch.Size([14, 512]), mode=val
[DEBUG rank=0] Starting NxN sim matrix with 28 items.
[DEBUG rank=0] NxN sim matrix done. shape=torch.Size([28, 28])
[DEBUG rank=0] Completed retrieval metrics & logging for val at epoch=3
[DEBUG] rank=0 => Logged val metrics to W&B

Saved latest checkpoint at epoch 4 to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0006150673437909941_20250206-035120_4wuf6qsw/checkpoints/checkpoint.pt
