pipeline_project: "DeepCORO_clip"
base_checkpoint_path: outputs
# Training parameters
epochs: 30
num_workers: 10
debug: false
use_amp: true
period: 2
run_mode: train
batch_size: 16
# Dataset parameters
data_filename: "output_dataset/siglip_generated/videos.csv"
root: "."
target_label: null
datapoint_loc_label: "FileName"
frames: 16
stride: 1
aggregate_videos_tokens: true
per_video_pool: false
data_mean: [105.67617, 105.67617, 105.67617]
data_std: [38.953922, 38.953922, 38.953922]
multi_video: false
num_videos: 1
groupby_column: "StudyInstanceUID"
shuffle_videos: true
siglip_texts_path: "output_dataset/siglip_generated/texts.csv"
siglip_max_positive_per_video: 15
siglip_negatives_per_video: 0
siglip_round_robin_sampling: true
siglip_max_segments_per_video: 15
# =============================================================================
# FIX #1: Balanced severity weights (max 3x ratio instead of 500x)
# Previous: normal=0.1, severe=50 -> 500x ratio caused collapse to severe
# =============================================================================
siglip_positive_severity_weights:
  normal: 1.0 # Base weight (was 0.1)
  mild: 1.5 # 1.5x normal (was 5.0 = 50x)
  moderate: 2.0 # 2x normal (was 25.0 = 250x)
  severe: 3.0 # 3x normal (was 50.0 = 500x)
  critical: 3.0 # 3x normal (was 50.0 = 500x)
  cto: 3.0 # 3x normal (was 50.0 = 500x)
siglip_enable_severity_weighting: true
siglip_normal_as_negative: false
siglip_positive_loss_weight: 1.0
siglip_negative_loss_weight: 1.0
siglip_auto_positive_loss_weight: true
# =============================================================================
# FIX #2: Entropy regularization to prevent embedding collapse
# Adds penalty when prediction distribution becomes too peaked
# =============================================================================
siglip_entropy_regularization: true
siglip_entropy_weight: 0.1 # Weight for entropy loss term
siglip_min_entropy_threshold: 2.0 # Only penalize if entropy drops below this
# Seed
seed: 42
# Model parameters
model_name: "mvit"
pretrained: true
# =============================================================================
# FIX #3: Lower learning rate (halved from original)
# =============================================================================
optimizer: "AdamW"
scheduler_name: "cosine_with_hard_restarts_with_warmup"
lr: 0.000004 # Halved from 8.4e-6 to prevent overshooting
lr_step_period: 15
factor: 0.14617805853947136
# Multi-loss configuration
loss_name: "siglip_pairwise"
loss_array:
  - siglip_pairwise: 1.0
  - locca_caption: 0.5
# LocCa Decoder configuration
locca_enabled: true
locca_num_layers: 4
locca_d_model: 512
locca_num_heads: 8
locca_dropout: 0.1
locca_max_seq_len: 256
tree_loss_enabled: false
tree_loss_weight: 0
video_weight_decay: 1.0e-6
text_weight_decay: 1.0e-6
gradient_accumulation_steps: 1
num_warmup_percent: 0.1 # Longer warmup (10% vs 5%)
num_hard_restarts_cycles: 2
warm_restart_tmult: 1
max_grad_norm: 0.5
video_max_grad_norm: 0.25
text_max_grad_norm: 0.7
# Model architecture parameters
num_heads: 16
aggregator_depth: 2
temperature: 0.1 # Slightly lower temp for sharper gradients
dropout: 0.1
video_freeze_ratio: 0.9 # Keep most of video encoder frozen
text_freeze_ratio: 0.7
# Checkpointing
resume_training: false
checkpoint: "outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt"
output_dir: outputs
save_best: "loss"
# Metrics
recall_k: [1, 5, 10, 50]
ndcg_k: [5]
# Data augmentation
rand_augment: true
resize: 224
apply_mask: false
# wandb parameters
tag: "mvit_balanced_weights_entropy_reg"
name: "dev_deep_coro_clip_siglip_balanced"
project: "dev_deep_coro_clip_single_video"
entity: "mhi_ai"
use_wandb: true
# Inference parameters
topk: 5
text_embeddings_path: "/media/data1/datasets/ECG_Tokenizer/utils/inference/reports_embeddings.pt"
metadata_path: "/media/data1/datasets/ECG_Tokenizer/utils/inference/reports_metadata.parquet"
inference_results_path: "checkpoints/inference/"
