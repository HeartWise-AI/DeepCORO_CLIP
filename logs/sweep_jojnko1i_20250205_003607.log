Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=True, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=5.797324418552144e-05, optimizer='RAdam', scheduler_type='cosine', lr_step_period=15, factor=0.20184570160501583, video_weight_decay=1.5371423917784037e-05, text_weight_decay=5.756226152790025e-07, loss_name='contrastive', temperature=0.08401050405821836, dropout=0.25273337760796655, video_freeze_ratio=0.7195109949025718, text_freeze_ratio=0.7490053344054506, num_heads=4, aggregator_depth=3, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=5.797324418552144e-05, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.08401050405821836, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=True, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.7195109949025718, text_freeze_ratio=0.7490053344054506, dropout=0.25273337760796655, num_heads=4, aggregator_depth=3, optimizer='RAdam', scheduler_type='cosine', lr_step_period=15, factor=0.20184570160501583, video_weight_decay=1.5371423917784037e-05, text_weight_decay=5.756226152790025e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 5.797324418552144e-05, 'batch_size': 10, 'epochs': 20, "
 "'num_workers': 16, 'debug': False, 'temperature': 0.08401050405821836, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 2, 'multi_video': True, 'num_videos': 4, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.7195109949025718, "
 "'text_freeze_ratio': 0.7490053344054506, 'dropout': 0.25273337760796655, "
 "'num_heads': 4, 'aggregator_depth': 3, 'optimizer': 'RAdam', "
 "'scheduler_type': 'cosine', 'lr_step_period': 15, 'factor': "
 "0.20184570160501583, 'video_weight_decay': 1.5371423917784037e-05, "
 "'text_weight_decay': 5.756226152790025e-07, 'output_dir': 'outputs', 'seed': "
 "42, 'use_amp': True, 'device': 'cuda', 'period': 1, 'loss_name': "
 "'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], 'rand_augment': True, "
 "'resize': 224, 'apply_mask': False, 'view_count': None, 'save_best': 'loss', "
 "'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
===========================

f0a85bca3128:125816:125816 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:125816:125816 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:125816:125816 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:125816:125816 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:125816:125816 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:125816:128578 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:125816:128578 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:125816:128578 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:125816:128578 [0] NCCL INFO Using network Socket
f0a85bca3128:125816:128578 [0] NCCL INFO ncclCommInitRank comm 0x5642e7e16b50 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x8d6276b554fb8e26 - Init START
f0a85bca3128:125816:128578 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:125816:128578 [0] NCCL INFO comm 0x5642e7e16b50 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:125816:128578 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:125816:128578 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:125816:128578 [0] NCCL INFO Connected all rings
f0a85bca3128:125816:128578 [0] NCCL INFO Connected all trees
f0a85bca3128:125816:128578 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:125816:128578 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:125816:128578 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:125816:128578 [0] NCCL INFO ncclCommInitRank comm 0x5642e7e16b50 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x8d6276b554fb8e26 - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 31286 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 3463 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   3,128 batches per GPU
Validation: 347 batches per GPU
Total:      3,475 batches per GPU

Batch Size: 10
Training: 31,280 videos per GPU
Validation: 3,470 videos per GPU
Total: 34,750 videos per GPU
===========================

Saved 3463 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_RAdam_lr5.797324418552144e-05_20250205-003632_0ty2w6do/val_texts.csv

New best model! Val Loss: 1.8643 (previous: inf)

Saved best checkpoint at epoch 1

Saved latest checkpoint at epoch 1

New best model! Val Loss: 1.7636 (previous: 1.8643)

Saved best checkpoint at epoch 2

Saved latest checkpoint at epoch 2

New best model! Val Loss: 1.6681 (previous: 1.7636)

Saved best checkpoint at epoch 3

Saved latest checkpoint at epoch 3

New best model! Val Loss: 1.6430 (previous: 1.6681)

Saved best checkpoint at epoch 4

Saved latest checkpoint at epoch 4

New best model! Val Loss: 1.5888 (previous: 1.6430)

Saved best checkpoint at epoch 5

Saved latest checkpoint at epoch 5

New best model! Val Loss: 1.5422 (previous: 1.5888)

Saved best checkpoint at epoch 6

Saved latest checkpoint at epoch 6

New best model! Val Loss: 1.4793 (previous: 1.5422)

Saved best checkpoint at epoch 7

Saved latest checkpoint at epoch 7

New best model! Val Loss: 1.4444 (previous: 1.4793)

Saved best checkpoint at epoch 8

Saved latest checkpoint at epoch 8

Saved latest checkpoint at epoch 9

New best model! Val Loss: 1.3827 (previous: 1.4444)

Saved best checkpoint at epoch 10

Saved latest checkpoint at epoch 10

Saved latest checkpoint at epoch 11

New best model! Val Loss: 1.3595 (previous: 1.3827)

Saved best checkpoint at epoch 12

Saved latest checkpoint at epoch 12

New best model! Val Loss: 1.3355 (previous: 1.3595)

Saved best checkpoint at epoch 13

Saved latest checkpoint at epoch 13

Saved latest checkpoint at epoch 14

Saved latest checkpoint at epoch 15

Saved latest checkpoint at epoch 16

Saved latest checkpoint at epoch 17

Saved latest checkpoint at epoch 18

Saved latest checkpoint at epoch 19
Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=0.00012211810498770622, optimizer='AdamW', scheduler_type='step', lr_step_period=10, factor=0.3379549811181397, video_weight_decay=1.1746317442544537e-07, text_weight_decay=2.74180880532747e-07, loss_name='contrastive', temperature=0.0846104082513673, dropout=0.2785977462044511, video_freeze_ratio=0.6791697172941733, text_freeze_ratio=0.7768385686210983, num_heads=4, aggregator_depth=1, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.00012211810498770622, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.0846104082513673, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.6791697172941733, text_freeze_ratio=0.7768385686210983, dropout=0.2785977462044511, num_heads=4, aggregator_depth=1, optimizer='AdamW', scheduler_type='step', lr_step_period=10, factor=0.3379549811181397, video_weight_decay=1.1746317442544537e-07, text_weight_decay=2.74180880532747e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.00012211810498770622, 'batch_size': 10, 'epochs': 20, "
 "'num_workers': 16, 'debug': False, 'temperature': 0.0846104082513673, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 2, 'multi_video': False, 'num_videos': 4, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.6791697172941733, "
 "'text_freeze_ratio': 0.7768385686210983, 'dropout': 0.2785977462044511, "
 "'num_heads': 4, 'aggregator_depth': 1, 'optimizer': 'AdamW', "
 "'scheduler_type': 'step', 'lr_step_period': 10, 'factor': "
 "0.3379549811181397, 'video_weight_decay': 1.1746317442544537e-07, "
 "'text_weight_decay': 2.74180880532747e-07, 'output_dir': 'outputs', 'seed': "
 "42, 'use_amp': True, 'device': 'cuda', 'period': 1, 'loss_name': "
 "'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], 'rand_augment': True, "
 "'resize': 224, 'apply_mask': False, 'view_count': None, 'save_best': 'loss', "
 "'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
===========================

f0a85bca3128:60998:60998 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:60998:60998 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:60998:60998 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:60998:60998 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:60998:60998 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:60998:63760 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:60998:63760 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:60998:63760 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:60998:63760 [0] NCCL INFO Using network Socket
f0a85bca3128:60998:63760 [0] NCCL INFO ncclCommInitRank comm 0x55ec539b1120 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf12db6b11de003b5 - Init START
f0a85bca3128:60998:63760 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:60998:63760 [0] NCCL INFO comm 0x55ec539b1120 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:60998:63760 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:60998:63760 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:60998:63760 [0] NCCL INFO Connected all rings
f0a85bca3128:60998:63760 [0] NCCL INFO Connected all trees
f0a85bca3128:60998:63760 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:60998:63760 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:60998:63760 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:60998:63760 [0] NCCL INFO ncclCommInitRank comm 0x55ec539b1120 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf12db6b11de003b5 - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'train':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'train': 142120
Final dataset size: 142120
Tokenizer initialized successfully
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'val':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'val': 15716
Final dataset size: 15716
Tokenizer initialized successfully

=== Dataset Information ===
Training:   14,212 batches per GPU
Validation: 1,572 batches per GPU
Total:      15,784 batches per GPU

Batch Size: 10
Training: 142,120 videos per GPU
Validation: 15,720 videos per GPU
Total: 157,840 videos per GPU
===========================

Saved 15716 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.00012211810498770622_20250206-021618_ci7gt00b/val_texts.csv
Error: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 178, in __getitem__
    video = load_video(
  File "/volume/DeepCORO_CLIP/utils/video.py", line 160, in load_video
    video = raug_composed(video)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 363, in forward
    img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 79, in _apply_op
    img = F.solarize(img, magnitude)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 1448, in solarize
    return F_t.solarize(img, threshold)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py", line 803, in solarize
    raise TypeError("Threshold should be less than bound of img.")
TypeError: Threshold should be less than bound of img.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 219, in __getitem__
    raise RuntimeError(f"Failed to load video {video_fname}: {str(e)}") from e
RuntimeError: Failed to load video /media/data1/ravram/MHI_CATH_DICOM_VIDEOS/2022/2.16.124.113611.1.118.1.1.6272228_1.3.12.2.1107.5.4.5.135214.30000022101704321354000000686.dcm.avi: Threshold should be less than bound of img.

f0a85bca3128:60998:63761 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:60998:68564 [0] NCCL INFO comm 0x55ec539b1120 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=0.00024063903132895471, optimizer='AdamW', scheduler_type='step', lr_step_period=10, factor=0.34447682354908965, video_weight_decay=1.758828620680781e-05, text_weight_decay=5.52717924335964e-07, loss_name='contrastive', temperature=0.08944158817288167, dropout=0.23308976564122544, video_freeze_ratio=0.6749875182172123, text_freeze_ratio=0.7738665140253072, num_heads=4, aggregator_depth=1, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.00024063903132895471, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.08944158817288167, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.6749875182172123, text_freeze_ratio=0.7738665140253072, dropout=0.23308976564122544, num_heads=4, aggregator_depth=1, optimizer='AdamW', scheduler_type='step', lr_step_period=10, factor=0.34447682354908965, video_weight_decay=1.758828620680781e-05, text_weight_decay=5.52717924335964e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.00024063903132895471, 'batch_size': 10, 'epochs': 20, "
 "'num_workers': 16, 'debug': False, 'temperature': 0.08944158817288167, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 2, 'multi_video': False, 'num_videos': 4, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.6749875182172123, "
 "'text_freeze_ratio': 0.7738665140253072, 'dropout': 0.23308976564122544, "
 "'num_heads': 4, 'aggregator_depth': 1, 'optimizer': 'AdamW', "
 "'scheduler_type': 'step', 'lr_step_period': 10, 'factor': "
 "0.34447682354908965, 'video_weight_decay': 1.758828620680781e-05, "
 "'text_weight_decay': 5.52717924335964e-07, 'output_dir': 'outputs', 'seed': "
 "42, 'use_amp': True, 'device': 'cuda', 'period': 1, 'loss_name': "
 "'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], 'rand_augment': True, "
 "'resize': 224, 'apply_mask': False, 'view_count': None, 'save_best': 'loss', "
 "'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
===========================

f0a85bca3128:68567:68567 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:68567:68567 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:68567:68567 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:68567:68567 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:68567:68567 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:68567:71329 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:68567:71329 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:68567:71329 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:68567:71329 [0] NCCL INFO Using network Socket
f0a85bca3128:68567:71329 [0] NCCL INFO ncclCommInitRank comm 0x55d9c12b7b90 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x3d4d06fa1a3d5ef9 - Init START
f0a85bca3128:68567:71329 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:68567:71329 [0] NCCL INFO comm 0x55d9c12b7b90 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:68567:71329 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:68567:71329 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:68567:71329 [0] NCCL INFO Connected all rings
f0a85bca3128:68567:71329 [0] NCCL INFO Connected all trees
f0a85bca3128:68567:71329 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:68567:71329 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:68567:71329 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:68567:71329 [0] NCCL INFO ncclCommInitRank comm 0x55d9c12b7b90 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x3d4d06fa1a3d5ef9 - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'train':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'train': 142120
Final dataset size: 142120
Tokenizer initialized successfully
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'val':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'val': 15716
Final dataset size: 15716
Tokenizer initialized successfully

=== Dataset Information ===
Training:   14,212 batches per GPU
Validation: 1,572 batches per GPU
Total:      15,784 batches per GPU

Batch Size: 10
Training: 142,120 videos per GPU
Validation: 15,720 videos per GPU
Total: 157,840 videos per GPU
===========================

Saved 15716 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.00024063903132895471_20250206-022237_n8pbvgjq/val_texts.csv
Error: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 178, in __getitem__
    video = load_video(
  File "/volume/DeepCORO_CLIP/utils/video.py", line 160, in load_video
    video = raug_composed(video)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 363, in forward
    img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 79, in _apply_op
    img = F.solarize(img, magnitude)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 1448, in solarize
    return F_t.solarize(img, threshold)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py", line 803, in solarize
    raise TypeError("Threshold should be less than bound of img.")
TypeError: Threshold should be less than bound of img.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 219, in __getitem__
    raise RuntimeError(f"Failed to load video {video_fname}: {str(e)}") from e
RuntimeError: Failed to load video /media/data1/ravram/MHI_CATH_DICOM_VIDEOS/2022/2.16.124.113611.1.118.1.1.6272228_1.3.12.2.1107.5.4.5.135214.30000022101704321354000000686.dcm.avi: Threshold should be less than bound of img.

f0a85bca3128:68567:71330 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:68567:76145 [0] NCCL INFO comm 0x55d9c12b7b90 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=0.0002806463415761168, optimizer='AdamW', scheduler_type='step', lr_step_period=15, factor=0.4665469563304386, video_weight_decay=1.0401630409384299e-07, text_weight_decay=1.790534263844414e-07, loss_name='contrastive', temperature=0.09610125964538124, dropout=0.29231922726401527, video_freeze_ratio=0.8549954773938917, text_freeze_ratio=0.8059828687600893, num_heads=4, aggregator_depth=2, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.0002806463415761168, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.09610125964538124, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.8549954773938917, text_freeze_ratio=0.8059828687600893, dropout=0.29231922726401527, num_heads=4, aggregator_depth=2, optimizer='AdamW', scheduler_type='step', lr_step_period=15, factor=0.4665469563304386, video_weight_decay=1.0401630409384299e-07, text_weight_decay=1.790534263844414e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.0002806463415761168, 'batch_size': 10, 'epochs': 20, "
 "'num_workers': 16, 'debug': False, 'temperature': 0.09610125964538124, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 2, 'multi_video': False, 'num_videos': 4, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.8549954773938917, "
 "'text_freeze_ratio': 0.8059828687600893, 'dropout': 0.29231922726401527, "
 "'num_heads': 4, 'aggregator_depth': 2, 'optimizer': 'AdamW', "
 "'scheduler_type': 'step', 'lr_step_period': 15, 'factor': "
 "0.4665469563304386, 'video_weight_decay': 1.0401630409384299e-07, "
 "'text_weight_decay': 1.790534263844414e-07, 'output_dir': 'outputs', 'seed': "
 "42, 'use_amp': True, 'device': 'cuda', 'period': 1, 'loss_name': "
 "'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], 'rand_augment': True, "
 "'resize': 224, 'apply_mask': False, 'view_count': None, 'save_best': 'loss', "
 "'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
===========================

f0a85bca3128:76148:76148 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:76148:76148 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:76148:76148 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:76148:76148 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:76148:76148 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:76148:78910 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:76148:78910 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:76148:78910 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:76148:78910 [0] NCCL INFO Using network Socket
f0a85bca3128:76148:78910 [0] NCCL INFO ncclCommInitRank comm 0x5643806bd570 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x141ad1c41bc528da - Init START
f0a85bca3128:76148:78910 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:76148:78910 [0] NCCL INFO comm 0x5643806bd570 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:76148:78910 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:76148:78910 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:76148:78910 [0] NCCL INFO Connected all rings
f0a85bca3128:76148:78910 [0] NCCL INFO Connected all trees
f0a85bca3128:76148:78910 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:76148:78910 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:76148:78910 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:76148:78910 [0] NCCL INFO ncclCommInitRank comm 0x5643806bd570 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x141ad1c41bc528da - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'train':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'train': 142120
Final dataset size: 142120
Tokenizer initialized successfully
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'val':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'val': 15716
Final dataset size: 15716
Tokenizer initialized successfully

=== Dataset Information ===
Training:   14,212 batches per GPU
Validation: 1,572 batches per GPU
Total:      15,784 batches per GPU

Batch Size: 10
Training: 142,120 videos per GPU
Validation: 15,720 videos per GPU
Total: 157,840 videos per GPU
===========================

Saved 15716 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0002806463415761168_20250206-022545_54oi61ry/val_texts.csv
Error: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 178, in __getitem__
    video = load_video(
  File "/volume/DeepCORO_CLIP/utils/video.py", line 160, in load_video
    video = raug_composed(video)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 363, in forward
    img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 83, in _apply_op
    img = F.equalize(img)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 1515, in equalize
    return F_t.equalize(img)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py", line 895, in equalize
    raise TypeError(f"Only torch.uint8 image tensors are supported, but found {img.dtype}")
TypeError: Only torch.uint8 image tensors are supported, but found torch.float32

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 219, in __getitem__
    raise RuntimeError(f"Failed to load video {video_fname}: {str(e)}") from e
RuntimeError: Failed to load video /media/data1/ravram/MHI_CATH_DICOM_VIDEOS/2022/2.16.124.113611.1.118.1.1.6272228_1.3.12.2.1107.5.4.5.135214.30000022101704321354000000686.dcm.avi: Only torch.uint8 image tensors are supported, but found torch.float32

f0a85bca3128:76148:78911 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:76148:83330 [0] NCCL INFO comm 0x5643806bd570 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=20, num_workers=16, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', text_weight_decay=1e-05, video_weight_decay=0.0001)
Sweep config: SweepConfig(batch_size=10, lr=0.0004995896320981103, optimizer='AdamW', scheduler_type='step', lr_step_period=20, factor=0.2952868603307016, video_weight_decay=3.7534154035254344e-06, text_weight_decay=1.268777080999552e-07, loss_name='contrastive', temperature=0.05732056837030006, dropout=0.15673851482169265, video_freeze_ratio=0.7253004562241474, text_freeze_ratio=0.9014197233247778, num_heads=2, aggregator_depth=1, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.0004995896320981103, batch_size=10, epochs=20, num_workers=16, debug=False, temperature=0.05732056837030006, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=2, multi_video=False, num_videos=4, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.7253004562241474, text_freeze_ratio=0.9014197233247778, dropout=0.15673851482169265, num_heads=2, aggregator_depth=1, optimizer='AdamW', scheduler_type='step', lr_step_period=20, factor=0.2952868603307016, video_weight_decay=3.7534154035254344e-06, text_weight_decay=1.268777080999552e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=True, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.0004995896320981103, 'batch_size': 10, 'epochs': 20, "
 "'num_workers': 16, 'debug': False, 'temperature': 0.05732056837030006, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 2, 'multi_video': False, 'num_videos': 4, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.7253004562241474, "
 "'text_freeze_ratio': 0.9014197233247778, 'dropout': 0.15673851482169265, "
 "'num_heads': 2, 'aggregator_depth': 1, 'optimizer': 'AdamW', "
 "'scheduler_type': 'step', 'lr_step_period': 20, 'factor': "
 "0.2952868603307016, 'video_weight_decay': 3.7534154035254344e-06, "
 "'text_weight_decay': 1.268777080999552e-07, 'output_dir': 'outputs', 'seed': "
 "42, 'use_amp': True, 'device': 'cuda', 'period': 1, 'loss_name': "
 "'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], 'rand_augment': True, "
 "'resize': 224, 'apply_mask': False, 'view_count': None, 'save_best': 'loss', "
 "'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250114-190320_2o5xoevj/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
===========================

f0a85bca3128:83333:83333 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:83333:83333 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:83333:83333 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:83333:83333 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:83333:83333 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:83333:86095 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:83333:86095 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:83333:86095 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:83333:86095 [0] NCCL INFO Using network Socket
f0a85bca3128:83333:86095 [0] NCCL INFO ncclCommInitRank comm 0x5639ef982160 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0xc1dfcdb1d6b6b4fd - Init START
f0a85bca3128:83333:86095 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:83333:86095 [0] NCCL INFO comm 0x5639ef982160 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:83333:86095 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:83333:86095 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:83333:86095 [0] NCCL INFO Connected all rings
f0a85bca3128:83333:86095 [0] NCCL INFO Connected all trees
f0a85bca3128:83333:86095 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:83333:86095 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:83333:86095 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:83333:86095 [0] NCCL INFO ncclCommInitRank comm 0x5639ef982160 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0xc1dfcdb1d6b6b4fd - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'train':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'train': 142120
Final dataset size: 142120
Tokenizer initialized successfully
Using MViT backbone - forcing exactly 16 frames with stride=1

Available splits in dataset:
Split
train    142120
val       15716
Name: count, dtype: int64

Dataset loading statistics for split 'val':
Total rows in CSV: 157836
Valid files found: 157836
Matching split 'val': 15716
Final dataset size: 15716
Tokenizer initialized successfully

=== Dataset Information ===
Training:   14,212 batches per GPU
Validation: 1,572 batches per GPU
Total:      15,784 batches per GPU

Batch Size: 10
Training: 142,120 videos per GPU
Validation: 15,720 videos per GPU
Total: 157,840 videos per GPU
===========================

Saved 15716 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0004995896320981103_20250206-022903_44g8bsir/val_texts.csv
Error: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 178, in __getitem__
    video = load_video(
  File "/volume/DeepCORO_CLIP/utils/video.py", line 160, in load_video
    video = raug_composed(video)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 363, in forward
    img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/autoaugment.py", line 79, in _apply_op
    img = F.solarize(img, magnitude)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 1448, in solarize
    return F_t.solarize(img, threshold)
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py", line 803, in solarize
    raise TypeError("Threshold should be less than bound of img.")
TypeError: Threshold should be less than bound of img.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/volume/DeepCORO_CLIP/dataloaders/video_dataset.py", line 219, in __getitem__
    raise RuntimeError(f"Failed to load video {video_fname}: {str(e)}") from e
RuntimeError: Failed to load video /media/data1/ravram/MHI_CATH_DICOM_VIDEOS/2022/2.16.124.113611.1.118.1.1.6272228_1.3.12.2.1107.5.4.5.135214.30000022101704321354000000686.dcm.avi: Threshold should be less than bound of img.

f0a85bca3128:83333:86096 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:83333:90899 [0] NCCL INFO comm 0x5639ef982160 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
