{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "        columns_list = df.columns.values.tolist()\n",
    "        isnull_list = df.isnull().sum().values.tolist()\n",
    "        isunique_list = df.nunique().values.tolist()\n",
    "        dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "        list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "        df_stat_val = pd.DataFrame(list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"])\n",
    "        print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the specified CSV file\n",
    "csv_file_path = \"/media/data1/ravram/DeepCORO/processed_dataframes/ObjectRecon_SWIN3D_2016-2023_inference_predictions_with_df_metadata_and_report.csv\"\n",
    "df_predictions = pd.read_csv(csv_file_path)\n",
    "display(df_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Filtered labels to vessel names mapping\n",
    "labels_to_vessel_names = {\n",
    "    \"lad\": \"Left Anterior Descending\",\n",
    "    \"dist_lad\": \"Distal Left Anterior Descending\",\n",
    "    \"mid_lad\": \"Mid Left Anterior Descending\",\n",
    "    \"lcx\": \"Left Circumflex\",\n",
    "    \"dist_lcx\": \"Distal Left Circumflex\",\n",
    "    \"leftmain\": \"Left Main Coronary Artery\",\n",
    "    \"prox_rca\": \"Proximal Right Coronary Artery\",\n",
    "    \"mid_rca\": \"Mid Right Coronary Artery\",\n",
    "    \"dist_rca\": \"Distal Right Coronary Artery\",\n",
    "    \"posterolateral\": \"Posterolateral\",\n",
    "    \"pda\": \"Posterior Descending Artery\",\n",
    "}\n",
    "\n",
    "# Function to create the report for each row\n",
    "\n",
    "\n",
    "def create_report(row):\n",
    "    report_lines = []\n",
    "\n",
    "    # Combine percentages with vessel names for the selected labels\n",
    "    for label, vessel_name in labels_to_vessel_names.items():\n",
    "        if label in row:\n",
    "            percentage = row[label]\n",
    "            if pd.notna(percentage) and percentage != -1:\n",
    "                report_line = f\"{vessel_name}: {percentage}%\"\n",
    "                report_lines.append(report_line)\n",
    "\n",
    "    # Add coronary dominance\n",
    "    if \"coronary_dominance\" in row:\n",
    "        report_lines.append(f\"Coronary Dominance: {row['coronary_dominance']}\")\n",
    "\n",
    "    # Summarize Conclusion and Recommendation\n",
    "    if \"Conclusion\" in row:\n",
    "        report_lines.append(f\"Conclusion: {row['Conclusion']}\")\n",
    "    if \"Recommendation\" in row:\n",
    "        report_lines.append(f\"Recommendation: {row['Recommendation']}\")\n",
    "\n",
    "    # Join all lines into a single string\n",
    "    report = \"\\n\".join(report_lines)\n",
    "    return report\n",
    "\n",
    "\n",
    "# Apply the function to create the 'Report' column with tqdm progress bar\n",
    "tqdm.pandas(desc=\"Generating Reports\")\n",
    "df_predictions[\"Report\"] = df_predictions.progress_apply(create_report, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_file_path = \"data/reports/reports_with_alpha_separator.csv\"\n",
    "output_dir = os.path.dirname(output_file_path)\n",
    "\n",
    "# Check if the directory exists, if not create it\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(output_file_path):\n",
    "    df_non_nan_reports = df_predictions.dropna(subset=[\"Report\", \"Conclusion\", \"Recommendation\"])\n",
    "    # Filter the dataframe to keep only rows where 'object_value' is 5 or 9\n",
    "    df_non_nan_reports = df_non_nan_reports[df_non_nan_reports[\"object_value\"].isin([5, 9])]\n",
    "\n",
    "    display(df_non_nan_reports.Report.sample(10))\n",
    "    # Save the 'Report' column to a text file with 'α' as the separator\n",
    "    df_non_nan_reports.to_csv(output_file_path, sep=\"α\", index=False, header=True)\n",
    "else:\n",
    "    print(f\"File {output_file_path} already exists. Skipping report generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"data/reports/reports_with_alpha_separator.csv\"\n",
    "df = pd.read_csv(output_file_path, sep=\"α\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 rows from the dataframe\n",
    "df_sampled = df.sample(n=1000, random_state=42)\n",
    "\n",
    "# Add a new column 'split' with value 'train'\n",
    "df_sampled[\"Split\"] = \"train\"\n",
    "\n",
    "# Save the sampled dataframe to a new CSV file\n",
    "output_sampled_file_path = \"data/reports/reports_sampled_1000.csv\"\n",
    "df_sampled.to_csv(output_sampled_file_path, sep=\"α\", index=False)\n",
    "\n",
    "display(df_sampled.Split.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
