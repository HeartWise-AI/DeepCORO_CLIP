{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Prompt Dataset Generation for SigLIP Training\n",
    "\n",
    "This notebook demonstrates generating multiple prompts per video following the SigLIP-inspired approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Add dataset_creation to path\n",
    "sys.path.append('dataset_creation')\n",
    "\n",
    "from generate_dataset_multiprompt import (\n",
    "    generate_multiprompt_dataset,\n",
    "    process_dataset_multiprompt,\n",
    "    create_default_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration\n",
    "config = create_default_config()\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Full Dataset\n",
    "\n",
    "This will process the full parquet file and generate multiple prompts per video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the full dataset\n",
    "input_path = '/media/data1/datasets/DeepCoro/2b_CathReport_HEMO_MHI_MERGED_2017-2024_VIDEO_LEVEL.parquet'\n",
    "output_dir = 'outputs/multiprompt_full'\n",
    "\n",
    "# Note: This will take a while for the full dataset\n",
    "# Uncomment to run:\n",
    "# process_dataset_multiprompt(input_path, output_dir, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Sample Data\n",
    "\n",
    "Let's test with a smaller sample to verify the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample of data\n",
    "df_sample = pd.read_parquet(input_path).head(100)\n",
    "print(f\"Loaded {len(df_sample)} rows\")\n",
    "print(f\"Columns: {df_sample.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-prompts\n",
    "prompt_df = generate_multiprompt_dataset(df_sample)\n",
    "print(f\"Generated {len(prompt_df)} prompts from {len(df_sample)} videos\")\n",
    "print(f\"Average prompts per video: {len(prompt_df) / len(df_sample):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prompt distribution\n",
    "print(\"Prompt type distribution:\")\n",
    "print(prompt_df['prompt_type'].value_counts())\n",
    "print(\"\\nPrompt weights:\")\n",
    "print(prompt_df.groupby('prompt_type')['prompt_weight'].first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample prompts\n",
    "print(\"Sample prompts:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show examples of each prompt type\n",
    "for prompt_type in prompt_df['prompt_type'].unique():\n",
    "    sample = prompt_df[prompt_df['prompt_type'] == prompt_type].iloc[0]\n",
    "    print(f\"\\nType: {prompt_type} (weight={sample['prompt_weight']})\")\n",
    "    print(f\"Study: {sample['StudyInstanceUID']}\")\n",
    "    print(f\"Text: {sample['prompt_text']}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample output\n",
    "output_path = Path('outputs/multiprompt_sample.parquet')\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "prompt_df.to_parquet(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Type Details\n",
    "\n",
    "The system generates 4 types of prompts per video:\n",
    "\n",
    "1. **Global Summary** (weight=0.5): Complete study description preserving distribution\n",
    "2. **Abnormal Focus** (weight=1.0): Critical findings â‰¥70% stenosis for high-signal training\n",
    "3. **Atomic Lesions** (weight=0.6): Individual lesion descriptions for compositional understanding\n",
    "4. **Negative Coverage** (weight=0.6): Normal territory descriptions for comprehensive coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing all prompt types for one study\n",
    "study_id = prompt_df['StudyInstanceUID'].iloc[0]\n",
    "study_prompts = prompt_df[prompt_df['StudyInstanceUID'] == study_id]\n",
    "\n",
    "print(f\"All prompts for study {study_id}:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in study_prompts.iterrows():\n",
    "    print(f\"\\n[{row['prompt_type']}] (weight={row['prompt_weight']})\")\n",
    "    print(f\"  {row['prompt_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}