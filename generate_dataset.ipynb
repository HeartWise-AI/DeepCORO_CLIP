{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37827/441343652.py:9: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "        columns_list = df.columns.values.tolist()\n",
    "        isnull_list = df.isnull().sum().values.tolist()\n",
    "        isunique_list = df.nunique().values.tolist()\n",
    "        dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "        list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "        df_stat_val = pd.DataFrame(list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"])\n",
    "        print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37827/1212704483.py:3: DtypeWarning: Columns (5,6,11,24,28,34,35,39,44,46,47,50,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,249,250,253,254) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_predictions = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in df_predictions:\n",
      "- Unnamed: 0.1\n",
      "- Unnamed: 0\n",
      "- filename\n",
      "- y_hat\n",
      "- object_value\n",
      "- brand\n",
      "- sex\n",
      "- FPS\n",
      "- NumberOfFrames\n",
      "- date\n",
      "- study_time\n",
      "- series_time\n",
      "- birthdate\n",
      "- color_format\n",
      "- StudyID\n",
      "- StudyInstanceUID\n",
      "- SeriesInstanceUID\n",
      "- dicom_path\n",
      "- FileName\n",
      "- uint16_video\n",
      "- primary_angle\n",
      "- secondary_angle\n",
      "- width\n",
      "- height\n",
      "- pixel_spacing\n",
      "- distance_source_to_detector\n",
      "- distance_source_to_patient\n",
      "- estimated_radiographic_magnification_factor\n",
      "- table_motion\n",
      "- radiation_setting\n",
      "- image_pixel_spacing\n",
      "- Split\n",
      "- CathReport_MRN\n",
      "- EXAMEN_ID\n",
      "- Num Accession\n",
      "- date/heure\n",
      "- DICOMPath\n",
      "- AccessionNumber\n",
      "- ModalitiesInStudy\n",
      "- Patient_ID\n",
      "- QueryRetrieveLevel\n",
      "- StudyDate\n",
      "- StudyTime\n",
      "- year\n",
      "- patient_id_anon\n",
      "- dicom_id\n",
      "- Recommendation\n",
      "- Conclusion\n",
      "- fps\n",
      "- frame_time\n",
      "- series_description\n",
      "- External_Exam\n",
      "- angle_value\n",
      "- Unnamed: 0_y\n",
      "- coronary_dominance_logit\n",
      "- coronary_dominance\n",
      "- D2_stenosis\n",
      "- D3_stenosis\n",
      "- RVG1_stenosis\n",
      "- RVG2_stenosis\n",
      "- S1_stenosis\n",
      "- bx_stenosis\n",
      "- diagonal_stenosis\n",
      "- dist_lad_stenosis\n",
      "- dist_lcx_stenosis\n",
      "- dist_rca_stenosis\n",
      "- lad_stenosis\n",
      "- lcx_stenosis\n",
      "- leftmain_stenosis\n",
      "- lima_or_svg_stenosis\n",
      "- lvp_stenosis\n",
      "- marg_d_stenosis\n",
      "- mid_lad_stenosis\n",
      "- mid_rca_stenosis\n",
      "- om1_stenosis\n",
      "- om2_stenosis\n",
      "- om3_stenosis\n",
      "- pda_stenosis\n",
      "- posterolateral_stenosis\n",
      "- prox_rca_stenosis\n",
      "- D2_IFRHYPEREMIE\n",
      "- D3_IFRHYPEREMIE\n",
      "- RVG1_IFRHYPEREMIE\n",
      "- RVG2_IFRHYPEREMIE\n",
      "- S1_IFRHYPEREMIE\n",
      "- bx_IFRHYPEREMIE\n",
      "- diagonal_IFRHYPEREMIE\n",
      "- dist_lad_IFRHYPEREMIE\n",
      "- dist_lcx_IFRHYPEREMIE\n",
      "- dist_rca_IFRHYPEREMIE\n",
      "- lad_IFRHYPEREMIE\n",
      "- lcx_IFRHYPEREMIE\n",
      "- leftmain_IFRHYPEREMIE\n",
      "- lima_or_svg_IFRHYPEREMIE\n",
      "- lvp_IFRHYPEREMIE\n",
      "- marg_d_IFRHYPEREMIE\n",
      "- mid_lad_IFRHYPEREMIE\n",
      "- mid_rca_IFRHYPEREMIE\n",
      "- om1_IFRHYPEREMIE\n",
      "- om2_IFRHYPEREMIE\n",
      "- om3_IFRHYPEREMIE\n",
      "- pda_IFRHYPEREMIE\n",
      "- posterolateral_IFRHYPEREMIE\n",
      "- prox_rca_IFRHYPEREMIE\n",
      "- D2_calcif\n",
      "- D3_calcif\n",
      "- RVG1_calcif\n",
      "- RVG2_calcif\n",
      "- S1_calcif\n",
      "- bx_calcif\n",
      "- diagonal_calcif\n",
      "- dist_lad_calcif\n",
      "- dist_lcx_calcif\n",
      "- dist_rca_calcif\n",
      "- lad_calcif\n",
      "- lcx_calcif\n",
      "- leftmain_calcif\n",
      "- lima_or_svg_calcif\n",
      "- lvp_calcif\n",
      "- marg_d_calcif\n",
      "- mid_lad_calcif\n",
      "- mid_rca_calcif\n",
      "- om1_calcif\n",
      "- om2_calcif\n",
      "- om3_calcif\n",
      "- pda_calcif\n",
      "- posterolateral_calcif\n",
      "- prox_rca_calcif\n",
      "- D2_IFRBASAL\n",
      "- D3_IFRBASAL\n",
      "- RVG1_IFRBASAL\n",
      "- RVG2_IFRBASAL\n",
      "- S1_IFRBASAL\n",
      "- bx_IFRBASAL\n",
      "- diagonal_IFRBASAL\n",
      "- dist_lad_IFRBASAL\n",
      "- dist_lcx_IFRBASAL\n",
      "- dist_rca_IFRBASAL\n",
      "- lad_IFRBASAL\n",
      "- lcx_IFRBASAL\n",
      "- leftmain_IFRBASAL\n",
      "- lima_or_svg_IFRBASAL\n",
      "- lvp_IFRBASAL\n",
      "- marg_d_IFRBASAL\n",
      "- mid_lad_IFRBASAL\n",
      "- mid_rca_IFRBASAL\n",
      "- om1_IFRBASAL\n",
      "- om2_IFRBASAL\n",
      "- om3_IFRBASAL\n",
      "- pda_IFRBASAL\n",
      "- posterolateral_IFRBASAL\n",
      "- prox_rca_IFRBASAL\n",
      "- D2_CFRBASAL\n",
      "- D3_CFRBASAL\n",
      "- RVG1_CFRBASAL\n",
      "- RVG2_CFRBASAL\n",
      "- S1_CFRBASAL\n",
      "- bx_CFRBASAL\n",
      "- diagonal_CFRBASAL\n",
      "- dist_lad_CFRBASAL\n",
      "- dist_lcx_CFRBASAL\n",
      "- dist_rca_CFRBASAL\n",
      "- lad_CFRBASAL\n",
      "- lcx_CFRBASAL\n",
      "- leftmain_CFRBASAL\n",
      "- lima_or_svg_CFRBASAL\n",
      "- lvp_CFRBASAL\n",
      "- marg_d_CFRBASAL\n",
      "- mid_lad_CFRBASAL\n",
      "- mid_rca_CFRBASAL\n",
      "- om1_CFRBASAL\n",
      "- om2_CFRBASAL\n",
      "- om3_CFRBASAL\n",
      "- pda_CFRBASAL\n",
      "- posterolateral_CFRBASAL\n",
      "- prox_rca_CFRBASAL\n",
      "- D2_CFRHYPEREMIE\n",
      "- D3_CFRHYPEREMIE\n",
      "- RVG1_CFRHYPEREMIE\n",
      "- RVG2_CFRHYPEREMIE\n",
      "- S1_CFRHYPEREMIE\n",
      "- bx_CFRHYPEREMIE\n",
      "- diagonal_CFRHYPEREMIE\n",
      "- dist_lad_CFRHYPEREMIE\n",
      "- dist_lcx_CFRHYPEREMIE\n",
      "- dist_rca_CFRHYPEREMIE\n",
      "- lad_CFRHYPEREMIE\n",
      "- lcx_CFRHYPEREMIE\n",
      "- leftmain_CFRHYPEREMIE\n",
      "- lima_or_svg_CFRHYPEREMIE\n",
      "- lvp_CFRHYPEREMIE\n",
      "- marg_d_CFRHYPEREMIE\n",
      "- mid_lad_CFRHYPEREMIE\n",
      "- mid_rca_CFRHYPEREMIE\n",
      "- om1_CFRHYPEREMIE\n",
      "- om2_CFRHYPEREMIE\n",
      "- om3_CFRHYPEREMIE\n",
      "- pda_CFRHYPEREMIE\n",
      "- posterolateral_CFRHYPEREMIE\n",
      "- prox_rca_CFRHYPEREMIE\n",
      "- D2_FFRHYPEREMIE\n",
      "- D3_FFRHYPEREMIE\n",
      "- RVG1_FFRHYPEREMIE\n",
      "- RVG2_FFRHYPEREMIE\n",
      "- S1_FFRHYPEREMIE\n",
      "- bx_FFRHYPEREMIE\n",
      "- diagonal_FFRHYPEREMIE\n",
      "- dist_lad_FFRHYPEREMIE\n",
      "- dist_lcx_FFRHYPEREMIE\n",
      "- dist_rca_FFRHYPEREMIE\n",
      "- lad_FFRHYPEREMIE\n",
      "- lcx_FFRHYPEREMIE\n",
      "- leftmain_FFRHYPEREMIE\n",
      "- lima_or_svg_FFRHYPEREMIE\n",
      "- lvp_FFRHYPEREMIE\n",
      "- marg_d_FFRHYPEREMIE\n",
      "- mid_lad_FFRHYPEREMIE\n",
      "- mid_rca_FFRHYPEREMIE\n",
      "- om1_FFRHYPEREMIE\n",
      "- om2_FFRHYPEREMIE\n",
      "- om3_FFRHYPEREMIE\n",
      "- pda_FFRHYPEREMIE\n",
      "- posterolateral_FFRHYPEREMIE\n",
      "- prox_rca_FFRHYPEREMIE\n",
      "- D2_FFRBASAL\n",
      "- D3_FFRBASAL\n",
      "- RVG1_FFRBASAL\n",
      "- RVG2_FFRBASAL\n",
      "- S1_FFRBASAL\n",
      "- bx_FFRBASAL\n",
      "- diagonal_FFRBASAL\n",
      "- dist_lad_FFRBASAL\n",
      "- dist_lcx_FFRBASAL\n",
      "- dist_rca_FFRBASAL\n",
      "- lad_FFRBASAL\n",
      "- lcx_FFRBASAL\n",
      "- leftmain_FFRBASAL\n",
      "- lima_or_svg_FFRBASAL\n",
      "- lvp_FFRBASAL\n",
      "- marg_d_FFRBASAL\n",
      "- mid_lad_FFRBASAL\n",
      "- mid_rca_FFRBASAL\n",
      "- om1_FFRBASAL\n",
      "- om2_FFRBASAL\n",
      "- om3_FFRBASAL\n",
      "- pda_FFRBASAL\n",
      "- posterolateral_FFRBASAL\n",
      "- prox_rca_FFRBASAL\n",
      "- acute_coronary_occlusion\n",
      "- pci_regions\n",
      "- pontage\n",
      "- acute_inferior_mi\n",
      "- Examen\n",
      "- G_INDICATIONS\n",
      "- ACS\n",
      "- insuffisance_cardiaque\n",
      "- cardiogenic_shock\n"
     ]
    }
   ],
   "source": [
    "# Load the specified CSV file\n",
    "csv_file_path = \"/media/data1/ravram/DeepCORO/processed_dataframes/ObjectRecon_SWIN3D_2016-2023_inference_predictions_with_df_metadata_and_report.csv\"\n",
    "df_predictions = pd.read_csv(csv_file_path)\n",
    "print(\"Column names in df_predictions:\")\n",
    "for col in df_predictions.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist_lad_calcif\n",
       "-1                           673331\n",
       "-1                            34850\n",
       "Calcifications minimes        27917\n",
       "Pas de calcification           2206\n",
       "Calcifications modérées        1554\n",
       "Calcification importantes      1213\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_predictions.dist_lad_calcif.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lcx_IFRBASAL\n",
       "-1.00    739858\n",
       " 1.00       653\n",
       " 0.00       284\n",
       " 0.96       219\n",
       " 0.97        22\n",
       " 0.92        18\n",
       " 0.98        16\n",
       " 0.99         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_predictions.lcx_IFRBASAL.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925207/925207 [04:31<00:00, 3410.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "##############################################################################\n",
    "# 1) Vessel Definitions (full list)                                          #\n",
    "##############################################################################\n",
    "labels_to_vessel_names = {\n",
    "    \"D2_stenosis\": \"the D2 branch\",\n",
    "    \"D3_stenosis\": \"the D3 branch\",\n",
    "    \"RVG1_stenosis\": \"the first right ventricular branch (RVG1)\",\n",
    "    \"RVG2_stenosis\": \"the second right ventricular branch (RVG2)\",\n",
    "    \"S1_stenosis\": \"the first septal branch (S1)\",\n",
    "    \"bx_stenosis\": \"the bypass graft (Bx)\",\n",
    "    \"diagonal_stenosis\": \"the diagonal branch\",\n",
    "    \"dist_lad_stenosis\": \"the distal segment of the Left Anterior Descending (LAD) artery\",\n",
    "    \"dist_lcx_stenosis\": \"the distal branch of the Left Circumflex (LCX) artery\",\n",
    "    \"dist_rca_stenosis\": \"the distal portion of the Right Coronary Artery (RCA)\",\n",
    "    \"lad_stenosis\": \"the proximal segment of the Left Anterior Descending (LAD) artery\",\n",
    "    \"lcx_stenosis\": \"the proximal branch of the Left Circumflex (LCX) artery\",\n",
    "    \"leftmain_stenosis\": \"the Left Main Coronary Artery (LMCA)\",\n",
    "    \"lima_or_svg_stenosis\": \"the LIMA or SVG graft\",\n",
    "    \"lvp_stenosis\": \"the left ventricular posterior (LVP) branch\",\n",
    "    \"marg_d_stenosis\": \"the marginal (Marg D) branch\",\n",
    "    \"mid_lad_stenosis\": \"the mid segment of the Left Anterior Descending (LAD) artery\",\n",
    "    \"mid_rca_stenosis\": \"the mid portion of the Right Coronary Artery (RCA)\",\n",
    "    \"om1_stenosis\": \"the first obtuse marginal (OM1) branch\",\n",
    "    \"om2_stenosis\": \"the second obtuse marginal (OM2) branch\",\n",
    "    \"om3_stenosis\": \"the third obtuse marginal (OM3) branch\",\n",
    "    \"pda_stenosis\": \"the posterior descending artery (PDA)\",\n",
    "    \"posterolateral_stenosis\": \"the posterolateral branch\",\n",
    "    \"prox_rca_stenosis\": \"the proximal Right Coronary Artery (RCA)\",\n",
    "}\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2) Helper Formatting Functions                                             #\n",
    "##############################################################################\n",
    "\n",
    "def format_stenosis_statement(vessel_name: str, percentage: float) -> str:\n",
    "    \"\"\"\n",
    "    Return a natural-language statement about stenosis severity.\n",
    "    \"\"\"\n",
    "    if percentage == 0:\n",
    "        return f\"{vessel_name} appears free of significant stenosis (0%).\"\n",
    "    elif 0 < percentage < 50:\n",
    "        return f\"{vessel_name} shows mild stenosis (~{percentage}%).\"\n",
    "    elif 50 <= percentage < 70:\n",
    "        return f\"{vessel_name} shows moderate stenosis (~{percentage}%).\"\n",
    "    elif 70 <= percentage < 90:\n",
    "        return f\"{vessel_name} shows severe stenosis (~{percentage}%).\"\n",
    "    else:\n",
    "        return f\"{vessel_name} shows critical stenosis (~{percentage}%).\"\n",
    "\n",
    "\n",
    "def format_calcification_statement(vessel_name: str, calcif_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a calcification label into a natural-language sentence.\n",
    "    \"\"\"\n",
    "    text = calcif_str.lower().strip()\n",
    "    # Adjust these if your categories differ\n",
    "    if \"pas de calcification\" in text or \"no calcification\" in text:\n",
    "        return f\"No calcification is noted in {vessel_name}.\"\n",
    "    elif \"minimes\" in text:\n",
    "        return f\"There are minimal calcifications in {vessel_name}.\"\n",
    "    elif \"modérées\" in text or \"moderate\" in text:\n",
    "        return f\"There are moderate calcifications in {vessel_name}.\"\n",
    "    elif \"importantes\" in text or \"severe\" in text:\n",
    "        return f\"There are severe calcifications in {vessel_name}.\"\n",
    "    else:\n",
    "        # fallback if text doesn't match known categories\n",
    "        return f\"Calcifications present in {vessel_name}: '{calcif_str}'.\"\n",
    "\n",
    "\n",
    "def format_ifr_statement(vessel_name: str, ifr_value: float) -> str:\n",
    "    \"\"\"\n",
    "    Indicate normal IFR (> 0.89) or abnormal IFR (<= 0.89).\n",
    "    \"\"\"\n",
    "    ifr_str = f\"{ifr_value:.2f}\"\n",
    "    if ifr_value > 0.89:\n",
    "        return f\"IFR measurement in {vessel_name} is normal (~{ifr_str}).\"\n",
    "    else:\n",
    "        return f\"IFR measurement in {vessel_name} is abnormal (~{ifr_str}).\"\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 3) Main Report Function                                                    #\n",
    "##############################################################################\n",
    "\n",
    "def create_report(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Builds a multi-section report for each row, covering:\n",
    "      - Stenosis, Calcification, IFR (per vessel)\n",
    "      - Coronary dominance\n",
    "      - Conclusion\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    stenosis_list = []\n",
    "    calcif_list = []\n",
    "    ifr_list = []\n",
    "\n",
    "    # For every vessel in the dictionary, check for corresponding columns\n",
    "    #   prefix_stenosis, prefix_calcif, prefix_IFRBASAL\n",
    "    for stenosis_label, vessel_name in labels_to_vessel_names.items():\n",
    "        if stenosis_label not in row:\n",
    "            continue\n",
    "\n",
    "        # e.g. prefix = \"dist_lad\"\n",
    "        prefix = stenosis_label.replace(\"_stenosis\", \"\")\n",
    "\n",
    "        # 1) Stenosis\n",
    "        st_val = row[stenosis_label]\n",
    "        if pd.notna(st_val) and st_val != -1:\n",
    "            stenosis_list.append(format_stenosis_statement(vessel_name, float(st_val)))\n",
    "\n",
    "        # 2) Calcification\n",
    "        calcif_label = f\"{prefix}_calcif\"\n",
    "        if calcif_label in row:\n",
    "            calc_val = row[calcif_label]\n",
    "            # skip if -1 or blank\n",
    "            if isinstance(calc_val, str) and calc_val.strip() != \"-1\":\n",
    "                calcif_list.append(format_calcification_statement(vessel_name, calc_val))\n",
    "\n",
    "        # 3) IFR\n",
    "        ifr_label = f\"{prefix}_IFRBASAL\"\n",
    "        if ifr_label in row:\n",
    "            ifr_val = row[ifr_label]\n",
    "            if pd.notna(ifr_val) and ifr_val != -1:\n",
    "                ifr_list.append(format_ifr_statement(vessel_name, float(ifr_val)))\n",
    "\n",
    "    # Add them to report if not empty\n",
    "    if stenosis_list:\n",
    "        report_lines.append(\"Stenosis findings:\")\n",
    "        report_lines.extend(stenosis_list)\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "    if calcif_list:\n",
    "        report_lines.append(\"Calcification findings:\")\n",
    "        report_lines.extend(calcif_list)\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "    if ifr_list:\n",
    "        report_lines.append(\"IFR measurements:\")\n",
    "        report_lines.extend(ifr_list)\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "    # Coronary dominance\n",
    "    if \"coronary_dominance\" in row and pd.notna(row[\"coronary_dominance\"]):\n",
    "        dom_str = str(row[\"coronary_dominance\"]).replace(\"_\", \" \")\n",
    "        report_lines.append(f\"The coronary circulation is {dom_str}.\")\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "\n",
    "    # If no content at all, return a default\n",
    "    final_report = \"\\n\".join([line for line in report_lines if line.strip() != \"\"])\n",
    "    if not final_report.strip():\n",
    "        return \"No significant findings or additional data available.\"\n",
    "    return final_report\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 4) Usage Example                                                           #\n",
    "##############################################################################\n",
    "df_predictions[\"Report\"] = df_predictions.progress_apply(create_report, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stenosis findings:\n",
      "the D2 branch appears free of significant stenosis (0%).\n",
      "the D3 branch appears free of significant stenosis (0%).\n",
      "the first right ventricular branch (RVG1) appears free of significant stenosis (0%).\n",
      "the second right ventricular branch (RVG2) appears free of significant stenosis (0%).\n",
      "the first septal branch (S1) appears free of significant stenosis (0%).\n",
      "the bypass graft (Bx) appears free of significant stenosis (0%).\n",
      "the diagonal branch appears free of significant stenosis (0%).\n",
      "the distal segment of the Left Anterior Descending (LAD) artery appears free of significant stenosis (0%).\n",
      "the distal branch of the Left Circumflex (LCX) artery appears free of significant stenosis (0%).\n",
      "the distal portion of the Right Coronary Artery (RCA) appears free of significant stenosis (0%).\n",
      "the proximal segment of the Left Anterior Descending (LAD) artery appears free of significant stenosis (0%).\n",
      "the proximal branch of the Left Circumflex (LCX) artery appears free of significant stenosis (0%).\n",
      "the Left Main Coronary Artery (LMCA) appears free of significant stenosis (0%).\n",
      "the LIMA or SVG graft appears free of significant stenosis (0%).\n",
      "the left ventricular posterior (LVP) branch appears free of significant stenosis (0%).\n",
      "the marginal (Marg D) branch appears free of significant stenosis (0%).\n",
      "the mid segment of the Left Anterior Descending (LAD) artery shows severe stenosis (~80.0%).\n",
      "the mid portion of the Right Coronary Artery (RCA) appears free of significant stenosis (0%).\n",
      "the first obtuse marginal (OM1) branch appears free of significant stenosis (0%).\n",
      "the second obtuse marginal (OM2) branch appears free of significant stenosis (0%).\n",
      "the third obtuse marginal (OM3) branch appears free of significant stenosis (0%).\n",
      "the posterior descending artery (PDA) appears free of significant stenosis (0%).\n",
      "the posterolateral branch appears free of significant stenosis (0%).\n",
      "the proximal Right Coronary Artery (RCA) appears free of significant stenosis (0%).\n",
      "Calcification findings:\n",
      "There are minimal calcifications in the mid segment of the Left Anterior Descending (LAD) artery.\n",
      "The coronary circulation is right dominant.\n"
     ]
    }
   ],
   "source": [
    "print(df_predictions[\"Report\"].iloc[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_file_path = \"data/reports/reports_with_alpha_separator_with_Calcifc_Stenosis_IFR_20250108.csv\"\n",
    "output_dir = os.path.dirname(output_file_path)\n",
    "\n",
    "# Check if the directory exists, if not create it\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# Drop rows where 'External_Exam' is True\n",
    "df_predictions = df_predictions[df_predictions[\"External_Exam\"] != True]\n",
    "\n",
    "df_non_nan_reports = df_predictions.dropna(subset=[\"Report\"])\n",
    "# Filter the dataframe to keep only rows where 'object_value' is 5 or 9\n",
    "df_non_nan_reports = df_non_nan_reports[df_non_nan_reports[\"object_value\"].isin([5, 9])]\n",
    "\n",
    "\n",
    "df_non_nan_reports.to_csv(output_file_path, sep=\"α\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37827/142835430.py:2: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  df_non_nan_reports = pd.read_csv(output_file_path, sep=\"α\")\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"data/reports/reports_with_alpha_separator_with_Calcifc_Stenosis_IFR_20250108.csv\"\n",
    "df_non_nan_reports = pd.read_csv(output_file_path, sep=\"α\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37827/829866552.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_final = df_top5.groupby('StudyInstanceUID').apply(pick_values).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# First, sort the dataframe by 'series_time' and group by 'StudyInstanceUID'\n",
    "df_sorted = df_non_nan_reports.sort_values(by='series_time')\n",
    "\n",
    "# Group by 'StudyInstanceUID' and keep the top 5 earliest 'series_time'\n",
    "df_top5 = df_sorted.groupby('StudyInstanceUID').head(5)\n",
    "\n",
    "# Define a function to pick 3 rows with object_value == 5 and 2 rows with object_value == 9\n",
    "def pick_values(group):\n",
    "    # Filter rows where object_value == 5 and keep 3\n",
    "    group_5 = group[group['object_value'] == 5].head(3)\n",
    "    # Filter rows where object_value == 9 and keep 2\n",
    "    group_9 = group[group['object_value'] == 9].head(2)\n",
    "    # Concatenate the results\n",
    "    return pd.concat([group_5, group_9])\n",
    "\n",
    "# Apply the function to each group\n",
    "df_final = df_top5.groupby('StudyInstanceUID').apply(pick_values).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object_value\n",
       "5    88883\n",
       "9    39333\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_final.object_value.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Split\n",
       "train    311970\n",
       "val       35529\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split 70% of patients for train and 30% for validation\n",
    "unique_patients = df_non_nan_reports[\"CathReport_MRN\"].drop_duplicates()\n",
    "train_size = int(0.9 * len(unique_patients))\n",
    "train_patients = unique_patients.sample(n=train_size, random_state=42)\n",
    "val_patients = unique_patients.drop(train_patients.index)\n",
    "\n",
    "# Keep only the sampled patients in the dataframe\n",
    "df_sampled = df_non_nan_reports[\n",
    "    df_non_nan_reports[\"CathReport_MRN\"].isin(train_patients)\n",
    "    | df_non_nan_reports[\"CathReport_MRN\"].isin(val_patients)\n",
    "]\n",
    "\n",
    "# Sample 300 unique StudyInstanceUID from the already split dataset\n",
    "#unique_study_ids = df_sampled[\"StudyInstanceUID\"].drop_duplicates().sample(n=300, random_state=42)\n",
    "\n",
    "# Keep only the sampled StudyInstanceUIDs in the dataframe\n",
    "#df_sampled = df_sampled[df_sampled[\"StudyInstanceUID\"].isin(unique_study_ids)]\n",
    "\n",
    "# Assign split based on CathReport_MRN\n",
    "df_sampled.loc[df_sampled[\"CathReport_MRN\"].isin(train_patients), \"Split\"] = \"train\"\n",
    "df_sampled.loc[df_sampled[\"CathReport_MRN\"].isin(val_patients), \"Split\"] = \"val\"\n",
    "\n",
    "# Save the dataframe with the sampled StudyInstanceUIDs to a new CSV file\n",
    "output_sampled_file_path = \"data/reports/reports_with_alpha_separator_with_Calcifc_Stenosis_IFR_20250108.csv\"\n",
    "df_sampled.to_csv(output_sampled_file_path, sep=\"α\", index=False)\n",
    "\n",
    "display(df_sampled.Split.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sampled_file_path = pd.read_csv(\n",
    "    \"data/reports/reports_sampled_no_conclusion.csv\", sep=\"α\"\n",
    ")\n",
    "df_sampled = output_sampled_file_path.sample(96).reset_index()\n",
    "# Save the dataframe with split information to a new CSV file\n",
    "output_sampled_file_path = \"data/reports/reports_sampled_no_conclusion_96.csv\"\n",
    "df_sampled.to_csv(output_sampled_file_path, sep=\"α\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = pd.read_csv('data/reports/reports_with_alpha_separator_with_conclusion_and_more_details_20250108.csv', sep='α')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load PubMedBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n",
    "# Get a sample text from the dataframe\n",
    "sample_text = df_sampled['Report'].iloc[0]\n",
    "\n",
    "# Encode the text\n",
    "encoded = tokenizer(\n",
    "    sample_text,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Decode back to text to verify\n",
    "decoded = tokenizer.decode(encoded['input_ids'][0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full texts without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(\"\\nOriginal text (full):\")\n",
    "print(sample_text)\n",
    "print(\"\\nDecoded text (full):\")\n",
    "print(decoded)\n",
    "print(\"\\nEncoded tokens:\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
