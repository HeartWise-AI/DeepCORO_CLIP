Base config: BaseConfig(epochs=10, num_workers=12, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt')
Sweep config: SweepConfig(batch_size=10, lr=0.0001264202568713193, optimizer='AdamW', scheduler_type='step', lr_step_period=10, factor=0.4720695714876925, weight_decay=1.466655992220659e-06, loss_name='contrastive', temperature=0.06743292852135978, dropout=0.12146697587977906, video_freeze_ratio=0.8900812458575882, text_freeze_ratio=0.8395677593645636, num_heads=2, aggregator_depth=2, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.0001264202568713193, batch_size=10, epochs=10, num_workers=12, debug=False, temperature=0.06743292852135978, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.8900812458575882, text_freeze_ratio=0.8395677593645636, dropout=0.12146697587977906, num_heads=2, aggregator_depth=2, optimizer='AdamW', scheduler_type='step', lr_step_period=10, factor=0.4720695714876925, weight_decay=1.466655992220659e-06, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.0001264202568713193, 'batch_size': 10, 'epochs': 10, "
 "'num_workers': 12, 'debug': False, 'temperature': 0.06743292852135978, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 1, 'multi_video': True, 'num_videos': 5, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.8900812458575882, "
 "'text_freeze_ratio': 0.8395677593645636, 'dropout': 0.12146697587977906, "
 "'num_heads': 2, 'aggregator_depth': 2, 'optimizer': 'AdamW', "
 "'scheduler_type': 'step', 'lr_step_period': 10, 'factor': "
 "0.4720695714876925, 'weight_decay': 1.466655992220659e-06, 'output_dir': "
 "'outputs', 'seed': 42, 'use_amp': True, 'device': 'cuda', 'period': 1, "
 "'loss_name': 'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], "
 "'rand_augment': False, 'resize': 224, 'apply_mask': False, 'view_count': "
 "None, 'save_best': 'loss', 'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Stats dataset length: 13

Using 100 samples for statistics calculation
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
Calculated from 100 samples (102,760,448 pixels)
===========================

f0a85bca3128:70694:70694 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:70694:70694 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:70694:70694 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:70694:70694 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:70694:70694 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:70694:73491 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:70694:73491 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:70694:73491 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:70694:73491 [0] NCCL INFO Using network Socket
f0a85bca3128:70694:73491 [0] NCCL INFO ncclCommInitRank comm 0x55e9774d1d30 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x6c472bcee4d6f382 - Init START
f0a85bca3128:70694:73491 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:70694:73491 [0] NCCL INFO comm 0x55e9774d1d30 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:70694:73491 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:70694:73491 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:70694:73491 [0] NCCL INFO Connected all rings
f0a85bca3128:70694:73491 [0] NCCL INFO Connected all trees
f0a85bca3128:70694:73491 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:70694:73491 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:70694:73491 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:70694:73491 [0] NCCL INFO ncclCommInitRank comm 0x55e9774d1d30 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x6c472bcee4d6f382 - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 31286 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 3463 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   3,128 batches per GPU
Validation: 347 batches per GPU
Total:      3,475 batches per GPU

Batch Size: 10
Training: 31,280 videos per GPU
Validation: 3,470 videos per GPU
Total: 34,750 videos per GPU
===========================

Saved 3463 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.0001264202568713193_20250203-212249_wylhmtg6/val_texts.csv
Error: CUDA out of memory. Tried to allocate 7.29 GiB. GPU 0 has a total capacity of 47.53 GiB of which 4.06 GiB is free. Process 76601 has 43.45 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 25.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
f0a85bca3128:70694:73492 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:70694:5945 [0] NCCL INFO comm 0x55e9774d1d30 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=10, num_workers=12, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt')
Sweep config: SweepConfig(batch_size=10, lr=3.4394444509266096e-05, optimizer='RAdam', scheduler_type='cosine', lr_step_period=20, factor=0.4691180718836785, weight_decay=7.892552511711405e-07, loss_name='contrastive', temperature=0.05175668859108293, dropout=0.17860638071311313, video_freeze_ratio=0.7009147563305593, text_freeze_ratio=0.7772576101127918, num_heads=4, aggregator_depth=1, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=3.4394444509266096e-05, batch_size=10, epochs=10, num_workers=12, debug=False, temperature=0.05175668859108293, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.7009147563305593, text_freeze_ratio=0.7772576101127918, dropout=0.17860638071311313, num_heads=4, aggregator_depth=1, optimizer='RAdam', scheduler_type='cosine', lr_step_period=20, factor=0.4691180718836785, weight_decay=7.892552511711405e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 3.4394444509266096e-05, 'batch_size': 10, 'epochs': 10, "
 "'num_workers': 12, 'debug': False, 'temperature': 0.05175668859108293, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 1, 'multi_video': True, 'num_videos': 5, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.7009147563305593, "
 "'text_freeze_ratio': 0.7772576101127918, 'dropout': 0.17860638071311313, "
 "'num_heads': 4, 'aggregator_depth': 1, 'optimizer': 'RAdam', "
 "'scheduler_type': 'cosine', 'lr_step_period': 20, 'factor': "
 "0.4691180718836785, 'weight_decay': 7.892552511711405e-07, 'output_dir': "
 "'outputs', 'seed': 42, 'use_amp': True, 'device': 'cuda', 'period': 1, "
 "'loss_name': 'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], "
 "'rand_augment': False, 'resize': 224, 'apply_mask': False, 'view_count': "
 "None, 'save_best': 'loss', 'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Stats dataset length: 13

Using 100 samples for statistics calculation
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
Calculated from 100 samples (102,760,448 pixels)
===========================

f0a85bca3128:6078:6078 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:6078:6078 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:6078:6078 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:6078:6078 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:6078:6078 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:6078:8882 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:6078:8882 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:6078:8882 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:6078:8882 [0] NCCL INFO Using network Socket
f0a85bca3128:6078:8882 [0] NCCL INFO ncclCommInitRank comm 0x564a4a37f950 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x6cb2a5b9552e4d0e - Init START
f0a85bca3128:6078:8882 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:6078:8882 [0] NCCL INFO comm 0x564a4a37f950 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:6078:8882 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:6078:8882 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:6078:8882 [0] NCCL INFO Connected all rings
f0a85bca3128:6078:8882 [0] NCCL INFO Connected all trees
f0a85bca3128:6078:8882 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:6078:8882 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:6078:8882 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:6078:8882 [0] NCCL INFO ncclCommInitRank comm 0x564a4a37f950 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x6cb2a5b9552e4d0e - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 31286 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 3463 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   3,128 batches per GPU
Validation: 347 batches per GPU
Total:      3,475 batches per GPU

Batch Size: 10
Training: 31,280 videos per GPU
Validation: 3,470 videos per GPU
Total: 34,750 videos per GPU
===========================

Saved 3463 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_RAdam_lr3.4394444509266096e-05_20250203-231856_3byqjamw/val_texts.csv
Error: CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.53 GiB of which 4.39 GiB is free. Process 83060 has 43.11 GiB memory in use. Of the allocated memory 24.70 GiB is allocated by PyTorch, and 17.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
f0a85bca3128:6078:8883 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:6078:63939 [0] NCCL INFO comm 0x564a4a37f950 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=10, num_workers=12, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt')
Sweep config: SweepConfig(batch_size=10, lr=0.000155866089314026, optimizer='RAdam', scheduler_type='step', lr_step_period=10, factor=0.3611414837885215, weight_decay=2.609778884119513e-06, loss_name='contrastive', temperature=0.07657509492440237, dropout=0.2983689571097977, video_freeze_ratio=0.8450011726619492, text_freeze_ratio=0.747258804859518, num_heads=4, aggregator_depth=3, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.000155866089314026, batch_size=10, epochs=10, num_workers=12, debug=False, temperature=0.07657509492440237, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.8450011726619492, text_freeze_ratio=0.747258804859518, dropout=0.2983689571097977, num_heads=4, aggregator_depth=3, optimizer='RAdam', scheduler_type='step', lr_step_period=10, factor=0.3611414837885215, weight_decay=2.609778884119513e-06, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.000155866089314026, 'batch_size': 10, 'epochs': 10, "
 "'num_workers': 12, 'debug': False, 'temperature': 0.07657509492440237, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 1, 'multi_video': True, 'num_videos': 5, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.8450011726619492, "
 "'text_freeze_ratio': 0.747258804859518, 'dropout': 0.2983689571097977, "
 "'num_heads': 4, 'aggregator_depth': 3, 'optimizer': 'RAdam', "
 "'scheduler_type': 'step', 'lr_step_period': 10, 'factor': "
 "0.3611414837885215, 'weight_decay': 2.609778884119513e-06, 'output_dir': "
 "'outputs', 'seed': 42, 'use_amp': True, 'device': 'cuda', 'period': 1, "
 "'loss_name': 'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], "
 "'rand_augment': False, 'resize': 224, 'apply_mask': False, 'view_count': "
 "None, 'save_best': 'loss', 'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Stats dataset length: 13

Using 100 samples for statistics calculation
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
Calculated from 100 samples (102,760,448 pixels)
===========================

f0a85bca3128:63948:63948 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:63948:63948 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:63948:63948 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:63948:63948 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:63948:63948 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:63948:66325 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:63948:66325 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:63948:66325 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:63948:66325 [0] NCCL INFO Using network Socket
f0a85bca3128:63948:66325 [0] NCCL INFO ncclCommInitRank comm 0x5591ab59f430 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x14e97e6432e15f2e - Init START
f0a85bca3128:63948:66325 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:63948:66325 [0] NCCL INFO comm 0x5591ab59f430 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:63948:66325 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:63948:66325 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:63948:66325 [0] NCCL INFO Connected all rings
f0a85bca3128:63948:66325 [0] NCCL INFO Connected all trees
f0a85bca3128:63948:66325 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:63948:66325 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:63948:66325 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:63948:66325 [0] NCCL INFO ncclCommInitRank comm 0x5591ab59f430 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x14e97e6432e15f2e - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 31286 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 3463 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   3,128 batches per GPU
Validation: 347 batches per GPU
Total:      3,475 batches per GPU

Batch Size: 10
Training: 31,280 videos per GPU
Validation: 3,470 videos per GPU
Total: 34,750 videos per GPU
===========================

Saved 3463 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_RAdam_lr0.000155866089314026_20250204-011122_3qd4offq/val_texts.csv
Error: CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.53 GiB of which 3.21 GiB is free. Process 34836 has 44.29 GiB memory in use. Of the allocated memory 24.79 GiB is allocated by PyTorch, and 18.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
f0a85bca3128:63948:66326 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:63948:70255 [0] NCCL INFO comm 0x5591ab59f430 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=10, num_workers=12, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt')
Sweep config: SweepConfig(batch_size=10, lr=0.00010913862975077616, optimizer='AdamW', scheduler_type='cosine', lr_step_period=20, factor=0.4556394977821137, weight_decay=1.037578958670431e-06, loss_name='contrastive', temperature=0.08401849873137787, dropout=0.2690463115602265, video_freeze_ratio=0.6759296349508963, text_freeze_ratio=0.7958880065179224, num_heads=4, aggregator_depth=1, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.00010913862975077616, batch_size=10, epochs=10, num_workers=12, debug=False, temperature=0.08401849873137787, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.6759296349508963, text_freeze_ratio=0.7958880065179224, dropout=0.2690463115602265, num_heads=4, aggregator_depth=1, optimizer='AdamW', scheduler_type='cosine', lr_step_period=20, factor=0.4556394977821137, weight_decay=1.037578958670431e-06, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.00010913862975077616, 'batch_size': 10, 'epochs': 10, "
 "'num_workers': 12, 'debug': False, 'temperature': 0.08401849873137787, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 1, 'multi_video': True, 'num_videos': 5, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.6759296349508963, "
 "'text_freeze_ratio': 0.7958880065179224, 'dropout': 0.2690463115602265, "
 "'num_heads': 4, 'aggregator_depth': 1, 'optimizer': 'AdamW', "
 "'scheduler_type': 'cosine', 'lr_step_period': 20, 'factor': "
 "0.4556394977821137, 'weight_decay': 1.037578958670431e-06, 'output_dir': "
 "'outputs', 'seed': 42, 'use_amp': True, 'device': 'cuda', 'period': 1, "
 "'loss_name': 'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], "
 "'rand_augment': False, 'resize': 224, 'apply_mask': False, 'view_count': "
 "None, 'save_best': 'loss', 'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Stats dataset length: 13

Using 100 samples for statistics calculation
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
Calculated from 100 samples (102,760,448 pixels)
===========================

f0a85bca3128:70258:70258 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:70258:70258 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:70258:70258 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:70258:70258 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:70258:70258 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:70258:72638 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:70258:72638 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:70258:72638 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:70258:72638 [0] NCCL INFO Using network Socket
f0a85bca3128:70258:72638 [0] NCCL INFO ncclCommInitRank comm 0x558a545afb20 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x472c1e2bdbf3a36a - Init START
f0a85bca3128:70258:72638 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:70258:72638 [0] NCCL INFO comm 0x558a545afb20 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:70258:72638 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:70258:72638 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:70258:72638 [0] NCCL INFO Connected all rings
f0a85bca3128:70258:72638 [0] NCCL INFO Connected all trees
f0a85bca3128:70258:72638 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:70258:72638 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:70258:72638 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:70258:72638 [0] NCCL INFO ncclCommInitRank comm 0x558a545afb20 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x472c1e2bdbf3a36a - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 31286 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 3463 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   3,128 batches per GPU
Validation: 347 batches per GPU
Total:      3,475 batches per GPU

Batch Size: 10
Training: 31,280 videos per GPU
Validation: 3,470 videos per GPU
Total: 34,750 videos per GPU
===========================

Saved 3463 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.00010913862975077616_20250204-030332_50n3gx62/val_texts.csv
Error: CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.53 GiB of which 3.67 GiB is free. Process 49880 has 43.83 GiB memory in use. Of the allocated memory 24.71 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
f0a85bca3128:70258:72639 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:70258:76594 [0] NCCL INFO comm 0x558a545afb20 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
Base config: BaseConfig(epochs=10, num_workers=12, debug=False, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt')
Sweep config: SweepConfig(batch_size=10, lr=0.00014170202694642014, optimizer='AdamW', scheduler_type='cosine', lr_step_period=20, factor=0.4411473335288259, weight_decay=3.365825719973213e-07, loss_name='contrastive', temperature=0.06972066446406015, dropout=0.22978045134753072, video_freeze_ratio=0.7936923285111593, text_freeze_ratio=0.8415013004109114, num_heads=4, aggregator_depth=1, tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
HeartWise config: HeartWiseConfig(lr=0.00014170202694642014, batch_size=10, epochs=10, num_workers=12, debug=False, temperature=0.06972066446406015, data_filename='data/reports/reports_sampled_no_conclusion.csv', root='.', target_label='Report', datapoint_loc_label='FileName', frames=16, stride=1, multi_video=True, num_videos=5, groupby_column='StudyInstanceUID', shuffle_videos=True, model_name='mvit', pretrained=True, video_freeze_ratio=0.7936923285111593, text_freeze_ratio=0.8415013004109114, dropout=0.22978045134753072, num_heads=4, aggregator_depth=1, optimizer='AdamW', scheduler_type='cosine', lr_step_period=20, factor=0.4411473335288259, weight_decay=3.365825719973213e-07, output_dir='outputs', seed=42, use_amp=True, device='cuda', period=1, loss_name='contrastive', recall_k=[1, 5, 10], ndcg_k=[5], rand_augment=False, resize=224, apply_mask=False, view_count=None, save_best='loss', resume_training=False, checkpoint='outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', tag='mvit_pretrained', name='dev_deep_coro_clip', project='dev_deep_coro_clip', entity='mhi_ai')
running main with gpu 0
("Config: {'lr': 0.00014170202694642014, 'batch_size': 10, 'epochs': 10, "
 "'num_workers': 12, 'debug': False, 'temperature': 0.06972066446406015, "
 "'data_filename': 'data/reports/reports_sampled_no_conclusion.csv', 'root': "
 "'.', 'target_label': 'Report', 'datapoint_loc_label': 'FileName', 'frames': "
 "16, 'stride': 1, 'multi_video': True, 'num_videos': 5, 'groupby_column': "
 "'StudyInstanceUID', 'shuffle_videos': True, 'model_name': 'mvit', "
 "'pretrained': True, 'video_freeze_ratio': 0.7936923285111593, "
 "'text_freeze_ratio': 0.8415013004109114, 'dropout': 0.22978045134753072, "
 "'num_heads': 4, 'aggregator_depth': 1, 'optimizer': 'AdamW', "
 "'scheduler_type': 'cosine', 'lr_step_period': 20, 'factor': "
 "0.4411473335288259, 'weight_decay': 3.365825719973213e-07, 'output_dir': "
 "'outputs', 'seed': 42, 'use_amp': True, 'device': 'cuda', 'period': 1, "
 "'loss_name': 'contrastive', 'recall_k': [1, 5, 10], 'ndcg_k': [5], "
 "'rand_augment': False, 'resize': 224, 'apply_mask': False, 'view_count': "
 "None, 'save_best': 'loss', 'resume_training': False, 'checkpoint': "
 "'outputs/deepCORO_CLIP/DeepCORO_Clip_Sweep_Learnable_Temp_Full_mvit_b12_f16_RAdam_lr0.0001_20250105-140102_4prjnaxn/checkpoints/latest.pt', "
 "'tag': 'mvit_pretrained', 'name': 'dev_deep_coro_clip', 'project': "
 "'dev_deep_coro_clip', 'entity': 'mhi_ai'}")

=== Calculating Dataset Statistics ===
Stats dataset length: 13

Using 100 samples for statistics calculation
Frame count per video: 16

Dataset Statistics:
Mean: [101.12091064453125, 101.12091064453125, 101.12091064453125]
Std:  [39.847476959228516, 39.847476959228516, 39.847476959228516]
Calculated from 100 samples (102,760,448 pixels)
===========================

f0a85bca3128:76597:76597 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>
f0a85bca3128:76597:76597 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
f0a85bca3128:76597:76597 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
f0a85bca3128:76597:76597 [0] NCCL INFO NET/Plugin: Using internal network plugin.
f0a85bca3128:76597:76597 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
f0a85bca3128:76597:78974 [0] NCCL INFO Failed to open libibverbs.so[.1]
f0a85bca3128:76597:78974 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>
f0a85bca3128:76597:78974 [0] NCCL INFO Using non-device net plugin version 0
f0a85bca3128:76597:78974 [0] NCCL INFO Using network Socket
f0a85bca3128:76597:78974 [0] NCCL INFO ncclCommInitRank comm 0x5606c10cb970 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf254af261dcc17ef - Init START
f0a85bca3128:76597:78974 [0] NCCL INFO Setting affinity for GPU 0 to ff000000,00000000,ff000000
f0a85bca3128:76597:78974 [0] NCCL INFO comm 0x5606c10cb970 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 00/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 01/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 02/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 03/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 04/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 05/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 06/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 07/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 08/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 09/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 10/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 11/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 12/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 13/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 14/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 15/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 16/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 17/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 18/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 19/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 20/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 21/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 22/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 23/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 24/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 25/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 26/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 27/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 28/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 29/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 30/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Channel 31/32 :    0
f0a85bca3128:76597:78974 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f0a85bca3128:76597:78974 [0] NCCL INFO P2P Chunksize set to 131072
f0a85bca3128:76597:78974 [0] NCCL INFO Connected all rings
f0a85bca3128:76597:78974 [0] NCCL INFO Connected all trees
f0a85bca3128:76597:78974 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f0a85bca3128:76597:78974 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
f0a85bca3128:76597:78974 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
f0a85bca3128:76597:78974 [0] NCCL INFO ncclCommInitRank comm 0x5606c10cb970 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf254af261dcc17ef - Init COMPLETE
Rank: 0 - mean: tensor([101.1209, 101.1209, 101.1209]) - std: tensor([39.8475, 39.8475, 39.8475])
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 31286 studies in split='train'
[MultiVideoDataset] Missing 0 studies in split='train'
[MultiVideoDataset] resize=224
[MultiVideoDataset] mean=[101.12091064453125, 101.12091064453125, 101.12091064453125]
[MultiVideoDataset] std=[39.847476959228516, 39.847476959228516, 39.847476959228516]
[MultiVideoDataset] shuffle_videos=True
[MultiVideoDataset] seed=42
[MultiVideoDataset] seed=42 for random video sampling
[MultiVideoDataset] Found 3463 studies in split='val'
[MultiVideoDataset] Missing 0 studies in split='val'

=== Dataset Information ===
Training:   3,128 batches per GPU
Validation: 347 batches per GPU
Total:      3,475 batches per GPU

Batch Size: 10
Training: 31,280 videos per GPU
Validation: 3,470 videos per GPU
Total: 34,750 videos per GPU
===========================

Saved 3463 val texts to outputs/dev_deep_coro_clip/mvit_pretrained_mvit_b10_f16_AdamW_lr0.00014170202694642014_20250204-045043_abxy0l1m/val_texts.csv
Error: CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.53 GiB of which 4.20 GiB is free. Process 64090 has 43.30 GiB memory in use. Of the allocated memory 24.81 GiB is allocated by PyTorch, and 17.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
f0a85bca3128:76597:78975 [0] NCCL INFO [Service thread] Connection closed by localRank 0
f0a85bca3128:76597:82896 [0] NCCL INFO comm 0x5606c10cb970 rank 0 nranks 1 cudaDev 0 busId 1000 - Abort COMPLETE
